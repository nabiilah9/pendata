{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc5e227",
   "metadata": {},
   "source": [
    "# Binning (Diskritisasi) menggunakan K-Means Clustering  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e3c73",
   "metadata": {},
   "source": [
    "## Clusterisasi dengan K-Means  \n",
    "Clusterisasi dengan K-Means digunakan untuk mengelompokkan data pada fitur Sepal Length menjadi 4 kelompok (klaster) yaitu 0, 1, 2, 3, 4 berdasarkan tingkat kemiripan nilai. Proses ini dilakukan dengan cara mengelompokkan data yang memiliki nilai panjang sepal yang saling berdekatan ke dalam satu klaster yang sama. Nantinya setiap klaster yang terbentuk akan mewakili satu interval nilai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c38e8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah iterasi sampai konvergen: 2\n",
      "Inertia (SSE): 0.6416\n",
      "Silhouette Score: 0.5920\n",
      "\n",
      "Akurasi keseluruhan clustering terhadap label asli: 72.0000%\n",
      "\n",
      "Distribusi cluster per kelas:\n",
      "Cluster           0   1   2   3\n",
      "Class                          \n",
      "Iris-setosa      10   0  40   0\n",
      "Iris-versicolor  29   0   5  16\n",
      "Iris-virginica   10  12   1  27\n",
      "               class  cluster  predicted_class\n",
      "0        Iris-setosa        2      Iris-setosa\n",
      "1        Iris-setosa        2      Iris-setosa\n",
      "2        Iris-setosa        2      Iris-setosa\n",
      "3        Iris-setosa        2      Iris-setosa\n",
      "4        Iris-setosa        2      Iris-setosa\n",
      "5        Iris-setosa        0  Iris-versicolor\n",
      "6        Iris-setosa        2      Iris-setosa\n",
      "7        Iris-setosa        2      Iris-setosa\n",
      "8        Iris-setosa        2      Iris-setosa\n",
      "9        Iris-setosa        2      Iris-setosa\n",
      "10       Iris-setosa        0  Iris-versicolor\n",
      "11       Iris-setosa        2      Iris-setosa\n",
      "12       Iris-setosa        2      Iris-setosa\n",
      "13       Iris-setosa        2      Iris-setosa\n",
      "14       Iris-setosa        0  Iris-versicolor\n",
      "15       Iris-setosa        0  Iris-versicolor\n",
      "16       Iris-setosa        0  Iris-versicolor\n",
      "17       Iris-setosa        2      Iris-setosa\n",
      "18       Iris-setosa        0  Iris-versicolor\n",
      "19       Iris-setosa        2      Iris-setosa\n",
      "20       Iris-setosa        0  Iris-versicolor\n",
      "21       Iris-setosa        2      Iris-setosa\n",
      "22       Iris-setosa        2      Iris-setosa\n",
      "23       Iris-setosa        2      Iris-setosa\n",
      "24       Iris-setosa        2      Iris-setosa\n",
      "25       Iris-setosa        2      Iris-setosa\n",
      "26       Iris-setosa        2      Iris-setosa\n",
      "27       Iris-setosa        2      Iris-setosa\n",
      "28       Iris-setosa        2      Iris-setosa\n",
      "29       Iris-setosa        2      Iris-setosa\n",
      "30       Iris-setosa        2      Iris-setosa\n",
      "31       Iris-setosa        0  Iris-versicolor\n",
      "32       Iris-setosa        2      Iris-setosa\n",
      "33       Iris-setosa        0  Iris-versicolor\n",
      "34       Iris-setosa        2      Iris-setosa\n",
      "35       Iris-setosa        2      Iris-setosa\n",
      "36       Iris-setosa        0  Iris-versicolor\n",
      "37       Iris-setosa        2      Iris-setosa\n",
      "38       Iris-setosa        2      Iris-setosa\n",
      "39       Iris-setosa        2      Iris-setosa\n",
      "40       Iris-setosa        2      Iris-setosa\n",
      "41       Iris-setosa        2      Iris-setosa\n",
      "42       Iris-setosa        2      Iris-setosa\n",
      "43       Iris-setosa        2      Iris-setosa\n",
      "44       Iris-setosa        2      Iris-setosa\n",
      "45       Iris-setosa        2      Iris-setosa\n",
      "46       Iris-setosa        2      Iris-setosa\n",
      "47       Iris-setosa        2      Iris-setosa\n",
      "48       Iris-setosa        2      Iris-setosa\n",
      "49       Iris-setosa        2      Iris-setosa\n",
      "50   Iris-versicolor        3   Iris-virginica\n",
      "51   Iris-versicolor        3   Iris-virginica\n",
      "52   Iris-versicolor        3   Iris-virginica\n",
      "53   Iris-versicolor        0  Iris-versicolor\n",
      "54   Iris-versicolor        3   Iris-virginica\n",
      "55   Iris-versicolor        0  Iris-versicolor\n",
      "56   Iris-versicolor        3   Iris-virginica\n",
      "57   Iris-versicolor        2      Iris-setosa\n",
      "58   Iris-versicolor        3   Iris-virginica\n",
      "59   Iris-versicolor        2      Iris-setosa\n",
      "60   Iris-versicolor        2      Iris-setosa\n",
      "61   Iris-versicolor        0  Iris-versicolor\n",
      "62   Iris-versicolor        0  Iris-versicolor\n",
      "63   Iris-versicolor        0  Iris-versicolor\n",
      "64   Iris-versicolor        0  Iris-versicolor\n",
      "65   Iris-versicolor        3   Iris-virginica\n",
      "66   Iris-versicolor        0  Iris-versicolor\n",
      "67   Iris-versicolor        0  Iris-versicolor\n",
      "68   Iris-versicolor        3   Iris-virginica\n",
      "69   Iris-versicolor        0  Iris-versicolor\n",
      "70   Iris-versicolor        0  Iris-versicolor\n",
      "71   Iris-versicolor        0  Iris-versicolor\n",
      "72   Iris-versicolor        3   Iris-virginica\n",
      "73   Iris-versicolor        0  Iris-versicolor\n",
      "74   Iris-versicolor        3   Iris-virginica\n",
      "75   Iris-versicolor        3   Iris-virginica\n",
      "76   Iris-versicolor        3   Iris-virginica\n",
      "77   Iris-versicolor        3   Iris-virginica\n",
      "78   Iris-versicolor        0  Iris-versicolor\n",
      "79   Iris-versicolor        0  Iris-versicolor\n",
      "80   Iris-versicolor        0  Iris-versicolor\n",
      "81   Iris-versicolor        0  Iris-versicolor\n",
      "82   Iris-versicolor        0  Iris-versicolor\n",
      "83   Iris-versicolor        0  Iris-versicolor\n",
      "84   Iris-versicolor        0  Iris-versicolor\n",
      "85   Iris-versicolor        0  Iris-versicolor\n",
      "86   Iris-versicolor        3   Iris-virginica\n",
      "87   Iris-versicolor        3   Iris-virginica\n",
      "88   Iris-versicolor        0  Iris-versicolor\n",
      "89   Iris-versicolor        0  Iris-versicolor\n",
      "90   Iris-versicolor        0  Iris-versicolor\n",
      "91   Iris-versicolor        0  Iris-versicolor\n",
      "92   Iris-versicolor        0  Iris-versicolor\n",
      "93   Iris-versicolor        2      Iris-setosa\n",
      "94   Iris-versicolor        0  Iris-versicolor\n",
      "95   Iris-versicolor        0  Iris-versicolor\n",
      "96   Iris-versicolor        0  Iris-versicolor\n",
      "97   Iris-versicolor        3   Iris-virginica\n",
      "98   Iris-versicolor        2      Iris-setosa\n",
      "99   Iris-versicolor        0  Iris-versicolor\n",
      "100   Iris-virginica        3   Iris-virginica\n",
      "101   Iris-virginica        0  Iris-versicolor\n",
      "102   Iris-virginica        1   Iris-virginica\n",
      "103   Iris-virginica        3   Iris-virginica\n",
      "104   Iris-virginica        3   Iris-virginica\n",
      "105   Iris-virginica        1   Iris-virginica\n",
      "106   Iris-virginica        2      Iris-setosa\n",
      "107   Iris-virginica        1   Iris-virginica\n",
      "108   Iris-virginica        3   Iris-virginica\n",
      "109   Iris-virginica        1   Iris-virginica\n",
      "110   Iris-virginica        3   Iris-virginica\n",
      "111   Iris-virginica        3   Iris-virginica\n",
      "112   Iris-virginica        3   Iris-virginica\n",
      "113   Iris-virginica        0  Iris-versicolor\n",
      "114   Iris-virginica        0  Iris-versicolor\n",
      "115   Iris-virginica        3   Iris-virginica\n",
      "116   Iris-virginica        3   Iris-virginica\n",
      "117   Iris-virginica        1   Iris-virginica\n",
      "118   Iris-virginica        1   Iris-virginica\n",
      "119   Iris-virginica        0  Iris-versicolor\n",
      "120   Iris-virginica        3   Iris-virginica\n",
      "121   Iris-virginica        0  Iris-versicolor\n",
      "122   Iris-virginica        1   Iris-virginica\n",
      "123   Iris-virginica        3   Iris-virginica\n",
      "124   Iris-virginica        3   Iris-virginica\n",
      "125   Iris-virginica        1   Iris-virginica\n",
      "126   Iris-virginica        3   Iris-virginica\n",
      "127   Iris-virginica        0  Iris-versicolor\n",
      "128   Iris-virginica        3   Iris-virginica\n",
      "129   Iris-virginica        1   Iris-virginica\n",
      "130   Iris-virginica        1   Iris-virginica\n",
      "131   Iris-virginica        1   Iris-virginica\n",
      "132   Iris-virginica        3   Iris-virginica\n",
      "133   Iris-virginica        3   Iris-virginica\n",
      "134   Iris-virginica        0  Iris-versicolor\n",
      "135   Iris-virginica        1   Iris-virginica\n",
      "136   Iris-virginica        3   Iris-virginica\n",
      "137   Iris-virginica        3   Iris-virginica\n",
      "138   Iris-virginica        0  Iris-versicolor\n",
      "139   Iris-virginica        3   Iris-virginica\n",
      "140   Iris-virginica        3   Iris-virginica\n",
      "141   Iris-virginica        3   Iris-virginica\n",
      "142   Iris-virginica        0  Iris-versicolor\n",
      "143   Iris-virginica        3   Iris-virginica\n",
      "144   Iris-virginica        3   Iris-virginica\n",
      "145   Iris-virginica        3   Iris-virginica\n",
      "146   Iris-virginica        3   Iris-virginica\n",
      "147   Iris-virginica        3   Iris-virginica\n",
      "148   Iris-virginica        3   Iris-virginica\n",
      "149   Iris-virginica        0  Iris-versicolor\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import silhouette_score, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Baca data fitur dan label\n",
    "df_features = pd.read_excel(\"data_iris.xlsx\")   \n",
    "df_class = pd.read_excel(\"class.xlsx\")          \n",
    "\n",
    "# Gabungkan data fitur dan label\n",
    "df = df_features.copy()\n",
    "df['class'] = df_class['class']\n",
    "\n",
    "# Ambil hanya kolom sepal_length\n",
    "features = df[['sepal_length']]\n",
    "\n",
    "# Normalisasi fitur\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Clustering KMeans dengan 4 klaster\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "kmeans.fit(scaled_features)\n",
    "\n",
    "# Simpan hasil cluster ke dataframe\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "# Evaluasi\n",
    "print(f\"Jumlah iterasi sampai konvergen: {kmeans.n_iter_}\")\n",
    "print(f\"Inertia (SSE): {kmeans.inertia_:.4f}\")\n",
    "sil_score = silhouette_score(scaled_features, kmeans.labels_)\n",
    "print(f\"Silhouette Score: {sil_score:.4f}\")\n",
    "\n",
    "# Pemetaan cluster ke class mayoritas\n",
    "mapping = (\n",
    "    df.groupby('cluster')['class']\n",
    "    .agg(lambda x: x.mode()[0])\n",
    "    .to_dict()\n",
    ")\n",
    "df['predicted_class'] = df['cluster'].map(mapping)\n",
    "\n",
    "# Hitung akurasi prediksi clustering terhadap label asli\n",
    "y_true = df['class']\n",
    "y_pred = df['predicted_class']\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\nAkurasi keseluruhan clustering terhadap label asli: {acc:.4%}\")\n",
    "\n",
    "# Tampilkan distribusi cluster per kelas\n",
    "dist = pd.crosstab(df['class'], df['cluster'], rownames=['Class'], colnames=['Cluster'])\n",
    "print(\"\\nDistribusi cluster per kelas:\")\n",
    "print(dist)\n",
    "\n",
    "# Simpan hasil ke Excel\n",
    "df.to_excel(\"clus_dis.xlsx\", index=False)\n",
    "\n",
    "# Jika ingin tampilkan semua hasil\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df[['class', 'cluster', 'predicted_class']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1c0be",
   "metadata": {},
   "source": [
    "## Cari Min Max dan Centroid dari fitur sepal length  \n",
    "Pada tahap ini diperoleh informasi statistik yang mencakup nilai minimum (min), maksimum (max), dan centroid (nilai rata-rata) dari masing-masing cluster yang terbentuk. Statistik min dan max yang diperoleh dari hasil clustering ini nantinya dapat digunakan sebagai batas interval dalam proses diskritisasi fitur Sepal Length, sedangkan centroid dapat dimanfaatkan sebagai representasi numerik atau label diskrit dari masing-masing interval. Setiap data Sepal Length yang berada dalam suatu rentang (min hingga max) akan diberi label sesuai klaster tempatnya berada, menjadikan fitur tersebut tidak lagi berbentuk kontinu, melainkan sudah dalam bentuk kategori.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9c72558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistik Sepal Length per Cluster:\n",
      "         min  max  centroid\n",
      "cluster                    \n",
      "0        5.4  6.1  5.734694\n",
      "1        7.1  7.9  7.475000\n",
      "2        4.3  5.3  4.895652\n",
      "3        6.2  7.0  6.525581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Contoh Data\n",
    "df = pd.read_excel(\"clus_dis.xlsx\")\n",
    "features = df[['sepal_length']]\n",
    "\n",
    "# Normalisasi\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# KMeans Clustering\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "kmeans.fit(scaled_features)\n",
    "\n",
    "# Tambahkan hasil cluster ke data\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "# Ambil centroid dari hasil clustering (dalam skala normalisasi)\n",
    "centroids_scaled = kmeans.cluster_centers_\n",
    "\n",
    "# Konversi centroid ke skala asli\n",
    "centroids_original = scaler.inverse_transform(centroids_scaled)\n",
    "\n",
    "# Hitung min, max, dan centroid per klaster\n",
    "cluster_stats = df.groupby('cluster')['sepal_length'].agg(['min', 'max']).copy()\n",
    "cluster_stats['centroid'] = centroids_original.flatten()\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(\"\\nStatistik Sepal Length per Cluster:\")\n",
    "print(cluster_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ffb4a",
   "metadata": {},
   "source": [
    "Output tersebut adalah statistik dari fitur Sepal Length yang telah dikelompokkan ke dalam 4 klaster menggunakan KMeans Clustering. Untuk masing-masing klaster ditampilkan:  \n",
    "\n",
    "* min: Nilai terkecil dari Sepal Length dalam klaster tersebut. Bisa digunakan sebagai batas bawah interval.\n",
    "* max: Nilai terbesar dari Sepal Length dalam klaster tersebut. Bisa digunakan sebagai batas atas interval.\n",
    "* centroid: Nilai rata-rata (mean) dari Sepal Length dalam klaster tersebut, yang merupakan pusat dari klaster (hasil centroids_ dari KMeans). \n",
    "\n",
    "Statistik min max dapat digunakan sebagai interval untuk diskritisasi pada fitur sepal_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465f4e3b",
   "metadata": {},
   "source": [
    "## Hasil Diskritisasi fitur sepal length  \n",
    "Pada tahap ini dilakukan proses diskritisasi terhadap fitur numerik sepal_length berdasarkan hasil klasterisasi sebelumnya. Setiap data telah dikelompokkan ke dalam klaster menggunakan algoritma K-Means, dan hasil klaster tersebut kemudian digunakan untuk memberi label diskrit pada nilai sepal_length. Contoh, pada baris pertama, nilai sepal_length_original adalah 5.1 dan termasuk dalam klaster 2 berdasarkan rentang min max, sehingga label diskritisasi menjadi 'C'. Dengan pendekatan ini, fitur sepal_length yang semula berupa nilai kontinu kini telah dikonversi menjadi fitur kategori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84ef1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cluster sepal_length  sepal_length_original\n",
      "0          2            C                    5.1\n",
      "1          2            C                    4.9\n",
      "2          2            C                    4.7\n",
      "3          2            C                    4.6\n",
      "4          2            C                    5.0\n",
      "5          0            A                    5.4\n",
      "6          2            C                    4.6\n",
      "7          2            C                    5.0\n",
      "8          2            C                    4.4\n",
      "9          2            C                    4.9\n",
      "10         0            A                    5.4\n",
      "11         2            C                    4.8\n",
      "12         2            C                    4.8\n",
      "13         2            C                    4.3\n",
      "14         0            A                    5.8\n",
      "15         0            A                    5.7\n",
      "16         0            A                    5.4\n",
      "17         2            C                    5.1\n",
      "18         0            A                    5.7\n",
      "19         2            C                    5.1\n",
      "20         0            A                    5.4\n",
      "21         2            C                    5.1\n",
      "22         2            C                    4.6\n",
      "23         2            C                    5.1\n",
      "24         2            C                    4.8\n",
      "25         2            C                    5.0\n",
      "26         2            C                    5.0\n",
      "27         2            C                    5.2\n",
      "28         2            C                    5.2\n",
      "29         2            C                    4.7\n",
      "30         2            C                    4.8\n",
      "31         0            A                    5.4\n",
      "32         2            C                    5.2\n",
      "33         0            A                    5.5\n",
      "34         2            C                    4.9\n",
      "35         2            C                    5.0\n",
      "36         0            A                    5.5\n",
      "37         2            C                    4.9\n",
      "38         2            C                    4.4\n",
      "39         2            C                    5.1\n",
      "40         2            C                    5.0\n",
      "41         2            C                    4.5\n",
      "42         2            C                    4.4\n",
      "43         2            C                    5.0\n",
      "44         2            C                    5.1\n",
      "45         2            C                    4.8\n",
      "46         2            C                    5.1\n",
      "47         2            C                    4.6\n",
      "48         2            C                    5.3\n",
      "49         2            C                    5.0\n",
      "50         3            D                    7.0\n",
      "51         3            D                    6.4\n",
      "52         3            D                    6.9\n",
      "53         0            A                    5.5\n",
      "54         3            D                    6.5\n",
      "55         0            A                    5.7\n",
      "56         3            D                    6.3\n",
      "57         2            C                    4.9\n",
      "58         3            D                    6.6\n",
      "59         2            C                    5.2\n",
      "60         2            C                    5.0\n",
      "61         0            A                    5.9\n",
      "62         0            A                    6.0\n",
      "63         0            A                    6.1\n",
      "64         0            A                    5.6\n",
      "65         3            D                    6.7\n",
      "66         0            A                    5.6\n",
      "67         0            A                    5.8\n",
      "68         3            D                    6.2\n",
      "69         0            A                    5.6\n",
      "70         0            A                    5.9\n",
      "71         0            A                    6.1\n",
      "72         3            D                    6.3\n",
      "73         0            A                    6.1\n",
      "74         3            D                    6.4\n",
      "75         3            D                    6.6\n",
      "76         3            D                    6.8\n",
      "77         3            D                    6.7\n",
      "78         0            A                    6.0\n",
      "79         0            A                    5.7\n",
      "80         0            A                    5.5\n",
      "81         0            A                    5.5\n",
      "82         0            A                    5.8\n",
      "83         0            A                    6.0\n",
      "84         0            A                    5.4\n",
      "85         0            A                    6.0\n",
      "86         3            D                    6.7\n",
      "87         3            D                    6.3\n",
      "88         0            A                    5.6\n",
      "89         0            A                    5.5\n",
      "90         0            A                    5.5\n",
      "91         0            A                    6.1\n",
      "92         0            A                    5.8\n",
      "93         2            C                    5.0\n",
      "94         0            A                    5.6\n",
      "95         0            A                    5.7\n",
      "96         0            A                    5.7\n",
      "97         3            D                    6.2\n",
      "98         2            C                    5.1\n",
      "99         0            A                    5.7\n",
      "100        3            D                    6.3\n",
      "101        0            A                    5.8\n",
      "102        1            B                    7.1\n",
      "103        3            D                    6.3\n",
      "104        3            D                    6.5\n",
      "105        1            B                    7.6\n",
      "106        2            C                    4.9\n",
      "107        1            B                    7.3\n",
      "108        3            D                    6.7\n",
      "109        1            B                    7.2\n",
      "110        3            D                    6.5\n",
      "111        3            D                    6.4\n",
      "112        3            D                    6.8\n",
      "113        0            A                    5.7\n",
      "114        0            A                    5.8\n",
      "115        3            D                    6.4\n",
      "116        3            D                    6.5\n",
      "117        1            B                    7.7\n",
      "118        1            B                    7.7\n",
      "119        0            A                    6.0\n",
      "120        3            D                    6.9\n",
      "121        0            A                    5.6\n",
      "122        1            B                    7.7\n",
      "123        3            D                    6.3\n",
      "124        3            D                    6.7\n",
      "125        1            B                    7.2\n",
      "126        3            D                    6.2\n",
      "127        0            A                    6.1\n",
      "128        3            D                    6.4\n",
      "129        1            B                    7.2\n",
      "130        1            B                    7.4\n",
      "131        1            B                    7.9\n",
      "132        3            D                    6.4\n",
      "133        3            D                    6.3\n",
      "134        0            A                    6.1\n",
      "135        1            B                    7.7\n",
      "136        3            D                    6.3\n",
      "137        3            D                    6.4\n",
      "138        0            A                    6.0\n",
      "139        3            D                    6.9\n",
      "140        3            D                    6.7\n",
      "141        3            D                    6.9\n",
      "142        0            A                    5.8\n",
      "143        3            D                    6.8\n",
      "144        3            D                    6.7\n",
      "145        3            D                    6.7\n",
      "146        3            D                    6.3\n",
      "147        3            D                    6.5\n",
      "148        3            D                    6.2\n",
      "149        0            A                    5.9\n"
     ]
    }
   ],
   "source": [
    "# Pemetaan cluster ke label huruf\n",
    "cluster_to_label = {\n",
    "    0: 'A',\n",
    "    1: 'B',\n",
    "    2: 'C',\n",
    "    3: 'D'\n",
    "}\n",
    "\n",
    "# Salin kolom sepal_length asli ke kolom baru (agar data numerik tetap tersimpan)\n",
    "df['sepal_length_original'] = df['sepal_length']\n",
    "\n",
    "# Gantikan nilai sepal_length dengan huruf berdasarkan klaster\n",
    "df['sepal_length'] = df['cluster'].map(cluster_to_label)\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(df[['cluster', 'sepal_length', 'sepal_length_original']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f93d1",
   "metadata": {},
   "source": [
    "## Mengganti fitur sepal_length(numeriks) ke sepal_length (kategorikal)  \n",
    "Pada tahap ini, dilakukan proses transformasi fitur sepal_length dari tipe data numerik menjadi kategorikal. Proses ini diawali dengan membaca ulang data iris asli serta data kelas referensi. Data kemudian digabungkan agar fitur sepal_length dapat diproses bersama label kelasnya. Selanjutnya, nilai sepal_length dinormalisasi menggunakan Min-Max Scaler agar seluruh nilai berada dalam rentang 0 hingga 1. Proses normalisasi ini penting untuk meningkatkan performa algoritma K-Means, yang sensitif terhadap skala data.\n",
    "\n",
    "Setelah dinormalisasi, dilakukan proses klasterisasi menggunakan algoritma K-Means dengan jumlah klaster sebanyak empat. Setiap data kemudian memperoleh label klaster tertentu berdasarkan nilai sepal_length yang dimilikinya. Hasil klasterisasi disimpan dalam kolom baru bernama cluster.Kemudian, nilai klaster tersebut dipetakan ke dalam label kategorikal berupa huruf (‘A’, ‘B’, ‘C’, ‘D’) untuk menggantikan nilai numerik pada fitur sepal_length. Dengan demikian, fitur sepal_length yang semula bertipe numerik kini telah diubah menjadi fitur kategorikal atau diskrit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f0d510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  petal_length  petal_width sepal_length  sepal_width\n",
      "0      1           1.4          0.2            B          3.5\n",
      "1      2           1.4          0.2            B          3.0\n",
      "2      3           1.3          0.2            B          3.2\n",
      "3      4           1.5          0.2            B          3.1\n",
      "4      5           1.4          0.2            B          3.6\n",
      "5      6           1.7          0.4            A          3.9\n",
      "6      7           1.4          0.3            B          3.4\n",
      "7      8           1.5          0.2            B          3.4\n",
      "8      9           1.4          0.2            B          2.9\n",
      "9     10           1.5          0.1            B          3.1\n",
      "10    11           1.5          0.2            A          3.7\n",
      "11    12           1.6          0.2            B          3.4\n",
      "12    13           1.4          0.1            B          3.0\n",
      "13    14           1.1          0.1            B          3.0\n",
      "14    15           1.2          0.2            A          4.0\n",
      "15    16           1.5          0.4            A          4.4\n",
      "16    17           1.3          0.4            A          3.9\n",
      "17    18           1.4          0.3            B          3.5\n",
      "18    19           1.7          0.3            A          3.8\n",
      "19    20           1.5          0.3            B          3.8\n",
      "20    21           1.7          0.2            A          3.4\n",
      "21    22           1.5          0.4            B          3.7\n",
      "22    23           1.0          0.2            B          3.6\n",
      "23    24           1.7          0.5            B          3.3\n",
      "24    25           1.9          0.2            B          3.4\n",
      "25    26           1.6          0.2            B          3.0\n",
      "26    27           1.6          0.4            B          3.4\n",
      "27    28           1.5          0.2            B          3.5\n",
      "28    29           1.4          0.2            B          3.4\n",
      "29    30           1.6          0.2            B          3.2\n",
      "30    31           1.6          0.2            B          3.1\n",
      "31    32           1.5          0.4            A          3.4\n",
      "32    33           1.5          0.1            B          4.1\n",
      "33    34           1.4          0.2            A          4.2\n",
      "34    35           1.5          0.1            B          3.1\n",
      "35    36           1.2          0.2            B          3.2\n",
      "36    37           1.3          0.2            A          3.5\n",
      "37    38           1.5          0.1            B          3.1\n",
      "38    39           1.3          0.2            B          3.0\n",
      "39    40           1.5          0.2            B          3.4\n",
      "40    41           1.3          0.3            B          3.5\n",
      "41    42           1.3          0.3            B          2.3\n",
      "42    43           1.3          0.2            B          3.2\n",
      "43    44           1.6          0.6            B          3.5\n",
      "44    45           1.9          0.4            B          3.8\n",
      "45    46           1.4          0.3            B          3.0\n",
      "46    47           1.6          0.2            B          3.8\n",
      "47    48           1.4          0.2            B          3.2\n",
      "48    49           1.5          0.2            B          3.7\n",
      "49    50           1.4          0.2            B          3.3\n",
      "50    51           4.7          1.4            C          3.2\n",
      "51    52           4.5          1.5            C          3.2\n",
      "52    53           4.9          1.5            C          3.1\n",
      "53    54           4.0          1.3            A          2.3\n",
      "54    55           4.6          1.5            C          2.8\n",
      "55    56           4.5          1.3            A          2.8\n",
      "56    57           4.7          1.6            C          3.3\n",
      "57    58           3.3          1.0            B          2.4\n",
      "58    59           4.6          1.3            C          2.9\n",
      "59    60           3.9          1.4            B          2.7\n",
      "60    61           3.5          1.0            B          2.0\n",
      "61    62           4.2          1.5            A          3.0\n",
      "62    63           4.0          1.0            A          2.2\n",
      "63    64           4.7          1.4            A          2.9\n",
      "64    65           3.6          1.3            A          2.9\n",
      "65    66           4.4          1.4            C          3.1\n",
      "66    67           4.5          1.5            A          3.0\n",
      "67    68           4.1          1.0            A          2.7\n",
      "68    69           4.5          1.5            C          2.2\n",
      "69    70           3.9          1.1            A          2.5\n",
      "70    71           4.8          1.8            A          3.2\n",
      "71    72           4.0          1.3            A          2.8\n",
      "72    73           4.9          1.5            C          2.5\n",
      "73    74           4.7          1.2            A          2.8\n",
      "74    75           4.3          1.3            C          2.9\n",
      "75    76           4.4          1.4            C          3.0\n",
      "76    77           4.8          1.4            C          2.8\n",
      "77    78           5.0          1.7            C          3.0\n",
      "78    79           4.5          1.5            A          2.9\n",
      "79    80           3.5          1.0            A          2.6\n",
      "80    81           3.8          1.1            A          2.4\n",
      "81    82           3.7          1.0            A          2.4\n",
      "82    83           3.9          1.2            A          2.7\n",
      "83    84           5.1          1.6            A          2.7\n",
      "84    85           4.5          1.5            A          3.0\n",
      "85    86           4.5          1.6            A          3.4\n",
      "86    87           4.7          1.5            C          3.1\n",
      "87    88           4.4          1.3            C          2.3\n",
      "88    89           4.1          1.3            A          3.0\n",
      "89    90           4.0          1.3            A          2.5\n",
      "90    91           4.4          1.2            A          2.6\n",
      "91    92           4.6          1.4            A          3.0\n",
      "92    93           4.0          1.2            A          2.6\n",
      "93    94           3.3          1.0            B          2.3\n",
      "94    95           4.2          1.3            A          2.7\n",
      "95    96           4.2          1.2            A          3.0\n",
      "96    97           4.2          1.3            A          2.9\n",
      "97    98           4.3          1.3            C          2.9\n",
      "98    99           3.0          1.1            B          2.5\n",
      "99   100           4.1          1.3            A          2.8\n",
      "100  101           6.0          2.5            C          3.3\n",
      "101  102           5.1          1.9            A          2.7\n",
      "102  103           5.9          2.1            D          3.0\n",
      "103  104           5.6          1.8            C          2.9\n",
      "104  105           5.8          2.2            C          3.0\n",
      "105  106           6.6          2.1            D          3.0\n",
      "106  107           4.5          1.7            B          2.5\n",
      "107  108           6.3          1.8            D          2.9\n",
      "108  109           5.8          1.8            C          2.5\n",
      "109  110           6.1          2.5            D          3.6\n",
      "110  111           5.1          2.0            C          3.2\n",
      "111  112           5.3          1.9            C          2.7\n",
      "112  113           5.5          2.1            C          3.0\n",
      "113  114           5.0          2.0            A          2.5\n",
      "114  115           5.1          2.4            A          2.8\n",
      "115  116           5.3          2.3            C          3.2\n",
      "116  117           5.5          1.8            C          3.0\n",
      "117  118           6.7          2.2            D          3.8\n",
      "118  119           6.9          2.3            D          2.6\n",
      "119  120           5.0          1.5            A          2.2\n",
      "120  121           5.7          2.3            C          3.2\n",
      "121  122           4.9          2.0            A          2.8\n",
      "122  123           6.7          2.0            D          2.8\n",
      "123  124           4.9          1.8            C          2.7\n",
      "124  125           5.7          2.1            C          3.3\n",
      "125  126           6.0          1.8            D          3.2\n",
      "126  127           4.8          1.8            C          2.8\n",
      "127  128           4.9          1.8            A          3.0\n",
      "128  129           5.6          2.1            C          2.8\n",
      "129  130           5.8          1.6            D          3.0\n",
      "130  131           6.1          1.9            D          2.8\n",
      "131  132           6.4          2.0            D          3.8\n",
      "132  133           5.6          2.2            C          2.8\n",
      "133  134           5.1          1.5            C          2.8\n",
      "134  135           5.6          1.4            A          2.6\n",
      "135  136           6.1          2.3            D          3.0\n",
      "136  137           5.6          2.4            C          3.4\n",
      "137  138           5.5          1.8            C          3.1\n",
      "138  139           4.8          1.8            A          3.0\n",
      "139  140           5.4          2.1            C          3.1\n",
      "140  141           5.6          2.4            C          3.1\n",
      "141  142           5.1          2.3            C          3.1\n",
      "142  143           5.1          1.9            A          2.7\n",
      "143  144           5.9          2.3            C          3.2\n",
      "144  145           5.7          2.5            C          3.3\n",
      "145  146           5.2          2.3            C          3.0\n",
      "146  147           5.0          1.9            C          2.5\n",
      "147  148           5.2          2.0            C          3.0\n",
      "148  149           5.4          2.3            C          3.4\n",
      "149  150           5.1          1.8            A          3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df_features = pd.read_excel(\"clus_dis.xlsx\")\n",
    "df_class = pd.read_excel(\"class.xlsx\")\n",
    "\n",
    "# Gabungkan dengan class\n",
    "df = df_features.copy()\n",
    "df['class'] = df_class['class']\n",
    "\n",
    "# Clustering ulang fitur sepal_length\n",
    "features = df[['sepal_length']]\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "kmeans.fit(scaled_features)\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "# Map hasil cluster ke kategori\n",
    "cluster_to_category = {\n",
    "    0: 'A',\n",
    "    2: 'B',\n",
    "    3: 'C',\n",
    "    1: 'D'\n",
    "}\n",
    "df['sepal_length'] = df['cluster'].map(cluster_to_category)\n",
    "\n",
    "# Hapus kolom yang tidak perlu\n",
    "df_result = df.drop(columns=[col for col in ['cluster', 'class', 'predicted_class'] if col in df.columns])\n",
    "\n",
    "# Simpan\n",
    "df_result.to_excel(\"data_iris_sepal_kategori.xlsx\", index=False)\n",
    "\n",
    "# Tampilkan sebagian hasil\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d47048",
   "metadata": {},
   "source": [
    "## Melakukan proses diskritisasi dengan K-means clustering pada fitur lainya  \n",
    "Setelah sebelumnya dilakukan diskritisasi pada fitur sepal_length, tahap ini melanjutkan proses diskritisasi terhadap fitur numerik lainnya, yaitu sepal_width, petal_length, dan petal_width. Metode yang digunakan adalah K-Means Clustering, yang diterapkan secara terpisah pada masing-masing fitur. Pertama, data iris asli dan versi data yang sudah mengandung sepal_length kategorikal dibaca. Kemudian dibuat sebuah fungsi cluster_kategori_stat() yang bertugas melakukan normalisasi menggunakan Min-Max Scaler, proses clustering dengan KMeans, serta menghasilkan kategori huruf berdasarkan label cluster. Fungsi ini juga menghasilkan statistik nilai minimum, maksimum, dan centroid (rata-rata) untuk setiap cluster dari fitur yang didiskritisasi.  \n",
    "\n",
    "* Fitur sepal_width dikelompokkan ke dalam 3 kategori (‘A’, ‘B’, ‘C’).\n",
    "\n",
    "* Fitur petal_length dikelompokkan ke dalam 4 kategori (‘A’, ‘B’, ‘C’, ‘D’).\n",
    "\n",
    "* Fitur petal_width juga dikelompokkan ke dalam 3 kategori (‘A’, ‘B’, ‘C’)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3278806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil kategori disimpan ke 'data_iris_kategori_lengkap.xlsx'\n",
      "\n",
      "=== Statistik Sepal Width (3 kategori) ===\n",
      "          min  max  centroid\n",
      "kategori                    \n",
      "A         2.0  2.8  2.585106\n",
      "B         2.9  3.4  3.118987\n",
      "C         3.5  4.4  3.758333\n",
      "\n",
      "=== Statistik Petal Length (4 kategori) ===\n",
      "          min  max  centroid\n",
      "kategori                    \n",
      "A         1.0  1.9  1.464000\n",
      "B         3.0  4.3  3.884000\n",
      "C         4.4  5.3  4.808889\n",
      "D         5.4  6.9  5.903333\n",
      "\n",
      "=== Statistik Petal Width (3 kategori) ===\n",
      "          min  max  centroid\n",
      "kategori                    \n",
      "A         0.1  0.6  0.244000\n",
      "B         1.0  1.7  1.337037\n",
      "C         1.8  2.5  2.073913\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import numpy as np # Untuk np.nan jika perlu\n",
    "\n",
    "# --- 1. Baca data awal ---\n",
    "# Menggunakan nama file yang telah Anda sediakan\n",
    "try:\n",
    "    df_numerik = pd.read_excel(\"data_iris_sepal_kategori.xlsx\")\n",
    "    # Untuk df_kategori, kita akan memulainya dari df_numerik dan menambahkan kolom kategori.\n",
    "    # Asumsi: sepal_length sudah ada di df_numerik.\n",
    "    df_kategori = df_numerik[['id', 'sepal_length']].copy()\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading file: {e}. Pastikan file berada di direktori yang sama.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Fungsi bantu diskritisasi + mapping + statistik ---\n",
    "def discretize_kbins_stat(data_col, n_bins, label_map, strategy='kmeans'):\n",
    "    \"\"\"\n",
    "    Melakukan diskritisasi menggunakan KBinsDiscretizer dan menghitung statistik.\n",
    "\n",
    "    Args:\n",
    "        data_col (pd.Series): Kolom data numerik yang akan didiskritisasi.\n",
    "        n_bins (int): Jumlah bin/kategori yang diinginkan.\n",
    "        label_map (dict): Kamus untuk memetakan label numerik (0, 1, ...) ke label kategori (A, B, ...).\n",
    "        strategy (str): Strategi diskritisasi ('uniform', 'quantile', 'kmeans'). Default 'kmeans'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (pd.Series kategori, pd.DataFrame statistik)\n",
    "    \"\"\"\n",
    "    # Inisialisasi KBinsDiscretizer\n",
    "    # encode='ordinal' berarti outputnya adalah integer (0, 1, ...)\n",
    "    # strategy='kmeans' akan mencoba membuat bin berdasarkan klaster KMeans\n",
    "    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy=strategy)\n",
    "\n",
    "    # Melakukan fitting dan transformasi\n",
    "    # Reshape data_col agar sesuai dengan input yang diharapkan oleh scikit-learn (2D array)\n",
    "    labels_numeric = discretizer.fit_transform(data_col.values.reshape(-1, 1)).flatten().astype(int)\n",
    "\n",
    "    # Membuat seri kategori huruf\n",
    "    kategori_series = pd.Series(labels_numeric).map(label_map)\n",
    "\n",
    "    # Menghitung statistik min, max, centroid per cluster/bin\n",
    "    df_temp = pd.DataFrame({\n",
    "        'nilai_asli': data_col,\n",
    "        'cluster_id': labels_numeric # Menggunakan ID cluster/bin numerik\n",
    "    })\n",
    "\n",
    "    # Hitung statistik\n",
    "    stat = df_temp.groupby('cluster_id')['nilai_asli'].agg(['min', 'max', 'mean'])\n",
    "    stat = stat.rename(columns={'mean': 'centroid'}) # Mengganti nama 'mean' menjadi 'centroid'\n",
    "\n",
    "    # Tambahkan kolom kategori ke statistik\n",
    "    stat['kategori'] = stat.index.map(label_map)\n",
    "    stat = stat.set_index('kategori')\n",
    "\n",
    "    return kategori_series, stat\n",
    "\n",
    "# --- 3. Sepal Width (3 kategori) ---\n",
    "map_sepal_width = {0: 'A', 1: 'B', 2: 'C'}\n",
    "# Menggunakan 'kmeans' strategy untuk mendekati perilaku asli\n",
    "df_kategori['sepal_width'], stat_sepal_width = discretize_kbins_stat(\n",
    "    df_numerik['sepal_width'], 3, map_sepal_width, strategy='kmeans'\n",
    ")\n",
    "\n",
    "# --- 4. Petal Length (4 kategori) ---\n",
    "map_petal_length = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "df_kategori['petal_length'], stat_petal_length = discretize_kbins_stat(\n",
    "    df_numerik['petal_length'], 4, map_petal_length, strategy='kmeans'\n",
    ")\n",
    "\n",
    "# --- 5. Petal Width (3 kategori) ---\n",
    "map_petal_width = {0: 'A', 1: 'B', 2: 'C'}\n",
    "df_kategori['petal_width'], stat_petal_width = discretize_kbins_stat(\n",
    "    df_numerik['petal_width'], 3, map_petal_width, strategy='kmeans'\n",
    ")\n",
    "\n",
    "df_kategori.to_excel(\"data_iris_kategori_lengkap.xlsx\", index=False)\n",
    "print(\"Hasil kategori disimpan ke 'data_iris_kategori_lengkap.xlsx'\")\n",
    "\n",
    "\n",
    "# --- 7. Gabungkan semua statistik dan tampilkan ---\n",
    "print(\"\\n=== Statistik Sepal Width (3 kategori) ===\")\n",
    "print(stat_sepal_width[['min', 'max', 'centroid']])\n",
    "\n",
    "print(\"\\n=== Statistik Petal Length (4 kategori) ===\")\n",
    "print(stat_petal_length[['min', 'max', 'centroid']])\n",
    "\n",
    "print(\"\\n=== Statistik Petal Width (3 kategori) ===\")\n",
    "print(stat_petal_width[['min', 'max', 'centroid']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df347e",
   "metadata": {},
   "source": [
    "## Menampilkan semua data hasil diskritisasi setiap fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651898f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id sepal_length sepal_width petal_length petal_width\n",
      "0      1            B           C            A           A\n",
      "1      2            B           B            A           A\n",
      "2      3            B           B            A           A\n",
      "3      4            B           B            A           A\n",
      "4      5            B           C            A           A\n",
      "5      6            A           C            A           A\n",
      "6      7            B           B            A           A\n",
      "7      8            B           B            A           A\n",
      "8      9            B           B            A           A\n",
      "9     10            B           B            A           A\n",
      "10    11            A           C            A           A\n",
      "11    12            B           B            A           A\n",
      "12    13            B           B            A           A\n",
      "13    14            B           B            A           A\n",
      "14    15            A           C            A           A\n",
      "15    16            A           C            A           A\n",
      "16    17            A           C            A           A\n",
      "17    18            B           C            A           A\n",
      "18    19            A           C            A           A\n",
      "19    20            B           C            A           A\n",
      "20    21            A           B            A           A\n",
      "21    22            B           C            A           A\n",
      "22    23            B           C            A           A\n",
      "23    24            B           B            A           A\n",
      "24    25            B           B            A           A\n",
      "25    26            B           B            A           A\n",
      "26    27            B           B            A           A\n",
      "27    28            B           C            A           A\n",
      "28    29            B           B            A           A\n",
      "29    30            B           B            A           A\n",
      "30    31            B           B            A           A\n",
      "31    32            A           B            A           A\n",
      "32    33            B           C            A           A\n",
      "33    34            A           C            A           A\n",
      "34    35            B           B            A           A\n",
      "35    36            B           B            A           A\n",
      "36    37            A           C            A           A\n",
      "37    38            B           B            A           A\n",
      "38    39            B           B            A           A\n",
      "39    40            B           B            A           A\n",
      "40    41            B           C            A           A\n",
      "41    42            B           A            A           A\n",
      "42    43            B           B            A           A\n",
      "43    44            B           C            A           A\n",
      "44    45            B           C            A           A\n",
      "45    46            B           B            A           A\n",
      "46    47            B           C            A           A\n",
      "47    48            B           B            A           A\n",
      "48    49            B           C            A           A\n",
      "49    50            B           B            A           A\n",
      "50    51            C           B            C           B\n",
      "51    52            C           B            C           B\n",
      "52    53            C           B            C           B\n",
      "53    54            A           A            B           B\n",
      "54    55            C           A            C           B\n",
      "55    56            A           A            C           B\n",
      "56    57            C           B            C           B\n",
      "57    58            B           A            B           B\n",
      "58    59            C           B            C           B\n",
      "59    60            B           A            B           B\n",
      "60    61            B           A            B           B\n",
      "61    62            A           B            B           B\n",
      "62    63            A           A            B           B\n",
      "63    64            A           B            C           B\n",
      "64    65            A           B            B           B\n",
      "65    66            C           B            C           B\n",
      "66    67            A           B            C           B\n",
      "67    68            A           A            B           B\n",
      "68    69            C           A            C           B\n",
      "69    70            A           A            B           B\n",
      "70    71            A           B            C           C\n",
      "71    72            A           A            B           B\n",
      "72    73            C           A            C           B\n",
      "73    74            A           A            C           B\n",
      "74    75            C           B            B           B\n",
      "75    76            C           B            C           B\n",
      "76    77            C           A            C           B\n",
      "77    78            C           B            C           B\n",
      "78    79            A           B            C           B\n",
      "79    80            A           A            B           B\n",
      "80    81            A           A            B           B\n",
      "81    82            A           A            B           B\n",
      "82    83            A           A            B           B\n",
      "83    84            A           A            C           B\n",
      "84    85            A           B            C           B\n",
      "85    86            A           B            C           B\n",
      "86    87            C           B            C           B\n",
      "87    88            C           A            C           B\n",
      "88    89            A           B            B           B\n",
      "89    90            A           A            B           B\n",
      "90    91            A           A            C           B\n",
      "91    92            A           B            C           B\n",
      "92    93            A           A            B           B\n",
      "93    94            B           A            B           B\n",
      "94    95            A           A            B           B\n",
      "95    96            A           B            B           B\n",
      "96    97            A           B            B           B\n",
      "97    98            C           B            B           B\n",
      "98    99            B           A            B           B\n",
      "99   100            A           A            B           B\n",
      "100  101            C           B            D           C\n",
      "101  102            A           A            C           C\n",
      "102  103            D           B            D           C\n",
      "103  104            C           B            D           C\n",
      "104  105            C           B            D           C\n",
      "105  106            D           B            D           C\n",
      "106  107            B           A            C           B\n",
      "107  108            D           B            D           C\n",
      "108  109            C           A            D           C\n",
      "109  110            D           C            D           C\n",
      "110  111            C           B            C           C\n",
      "111  112            C           A            C           C\n",
      "112  113            C           B            D           C\n",
      "113  114            A           A            C           C\n",
      "114  115            A           A            C           C\n",
      "115  116            C           B            C           C\n",
      "116  117            C           B            D           C\n",
      "117  118            D           C            D           C\n",
      "118  119            D           A            D           C\n",
      "119  120            A           A            C           B\n",
      "120  121            C           B            D           C\n",
      "121  122            A           A            C           C\n",
      "122  123            D           A            D           C\n",
      "123  124            C           A            C           C\n",
      "124  125            C           B            D           C\n",
      "125  126            D           B            D           C\n",
      "126  127            C           A            C           C\n",
      "127  128            A           B            C           C\n",
      "128  129            C           A            D           C\n",
      "129  130            D           B            D           B\n",
      "130  131            D           A            D           C\n",
      "131  132            D           C            D           C\n",
      "132  133            C           A            D           C\n",
      "133  134            C           A            C           B\n",
      "134  135            A           A            D           B\n",
      "135  136            D           B            D           C\n",
      "136  137            C           B            D           C\n",
      "137  138            C           B            D           C\n",
      "138  139            A           B            C           C\n",
      "139  140            C           B            D           C\n",
      "140  141            C           B            D           C\n",
      "141  142            C           B            C           C\n",
      "142  143            A           A            C           C\n",
      "143  144            C           B            D           C\n",
      "144  145            C           B            D           C\n",
      "145  146            C           B            C           C\n",
      "146  147            C           A            C           C\n",
      "147  148            C           B            C           C\n",
      "148  149            C           B            D           C\n",
      "149  150            A           B            C           C\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Baca file Excel yang sudah berisi kategori\n",
    "df_kategori = pd.read_excel(\"data_iris_kategori_lengkap.xlsx\")\n",
    "\n",
    "# Tampilkan semua baris\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df_kategori)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5a94ff",
   "metadata": {},
   "source": [
    "## Klasifikasi Naive Bayes Data Diskrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bba9b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hasil Prediksi Kelas ===\n",
      "      id       kelas_asli   kelas_prediksi\n",
      "0      1      Iris-setosa      Iris-setosa\n",
      "1      2      Iris-setosa      Iris-setosa\n",
      "2      3      Iris-setosa      Iris-setosa\n",
      "3      4      Iris-setosa      Iris-setosa\n",
      "4      5      Iris-setosa      Iris-setosa\n",
      "5      6      Iris-setosa      Iris-setosa\n",
      "6      7      Iris-setosa      Iris-setosa\n",
      "7      8      Iris-setosa      Iris-setosa\n",
      "8      9      Iris-setosa      Iris-setosa\n",
      "9     10      Iris-setosa      Iris-setosa\n",
      "10    11      Iris-setosa      Iris-setosa\n",
      "11    12      Iris-setosa      Iris-setosa\n",
      "12    13      Iris-setosa      Iris-setosa\n",
      "13    14      Iris-setosa      Iris-setosa\n",
      "14    15      Iris-setosa      Iris-setosa\n",
      "15    16      Iris-setosa      Iris-setosa\n",
      "16    17      Iris-setosa      Iris-setosa\n",
      "17    18      Iris-setosa      Iris-setosa\n",
      "18    19      Iris-setosa      Iris-setosa\n",
      "19    20      Iris-setosa      Iris-setosa\n",
      "20    21      Iris-setosa      Iris-setosa\n",
      "21    22      Iris-setosa      Iris-setosa\n",
      "22    23      Iris-setosa      Iris-setosa\n",
      "23    24      Iris-setosa      Iris-setosa\n",
      "24    25      Iris-setosa      Iris-setosa\n",
      "25    26      Iris-setosa      Iris-setosa\n",
      "26    27      Iris-setosa      Iris-setosa\n",
      "27    28      Iris-setosa      Iris-setosa\n",
      "28    29      Iris-setosa      Iris-setosa\n",
      "29    30      Iris-setosa      Iris-setosa\n",
      "30    31      Iris-setosa      Iris-setosa\n",
      "31    32      Iris-setosa      Iris-setosa\n",
      "32    33      Iris-setosa      Iris-setosa\n",
      "33    34      Iris-setosa      Iris-setosa\n",
      "34    35      Iris-setosa      Iris-setosa\n",
      "35    36      Iris-setosa      Iris-setosa\n",
      "36    37      Iris-setosa      Iris-setosa\n",
      "37    38      Iris-setosa      Iris-setosa\n",
      "38    39      Iris-setosa      Iris-setosa\n",
      "39    40      Iris-setosa      Iris-setosa\n",
      "40    41      Iris-setosa      Iris-setosa\n",
      "41    42      Iris-setosa      Iris-setosa\n",
      "42    43      Iris-setosa      Iris-setosa\n",
      "43    44      Iris-setosa      Iris-setosa\n",
      "44    45      Iris-setosa      Iris-setosa\n",
      "45    46      Iris-setosa      Iris-setosa\n",
      "46    47      Iris-setosa      Iris-setosa\n",
      "47    48      Iris-setosa      Iris-setosa\n",
      "48    49      Iris-setosa      Iris-setosa\n",
      "49    50      Iris-setosa      Iris-setosa\n",
      "50    51  Iris-versicolor  Iris-versicolor\n",
      "51    52  Iris-versicolor  Iris-versicolor\n",
      "52    53  Iris-versicolor  Iris-versicolor\n",
      "53    54  Iris-versicolor  Iris-versicolor\n",
      "54    55  Iris-versicolor  Iris-versicolor\n",
      "55    56  Iris-versicolor  Iris-versicolor\n",
      "56    57  Iris-versicolor  Iris-versicolor\n",
      "57    58  Iris-versicolor  Iris-versicolor\n",
      "58    59  Iris-versicolor  Iris-versicolor\n",
      "59    60  Iris-versicolor  Iris-versicolor\n",
      "60    61  Iris-versicolor  Iris-versicolor\n",
      "61    62  Iris-versicolor  Iris-versicolor\n",
      "62    63  Iris-versicolor  Iris-versicolor\n",
      "63    64  Iris-versicolor  Iris-versicolor\n",
      "64    65  Iris-versicolor  Iris-versicolor\n",
      "65    66  Iris-versicolor  Iris-versicolor\n",
      "66    67  Iris-versicolor  Iris-versicolor\n",
      "67    68  Iris-versicolor  Iris-versicolor\n",
      "68    69  Iris-versicolor  Iris-versicolor\n",
      "69    70  Iris-versicolor  Iris-versicolor\n",
      "70    71  Iris-versicolor   Iris-virginica\n",
      "71    72  Iris-versicolor  Iris-versicolor\n",
      "72    73  Iris-versicolor  Iris-versicolor\n",
      "73    74  Iris-versicolor  Iris-versicolor\n",
      "74    75  Iris-versicolor  Iris-versicolor\n",
      "75    76  Iris-versicolor  Iris-versicolor\n",
      "76    77  Iris-versicolor  Iris-versicolor\n",
      "77    78  Iris-versicolor  Iris-versicolor\n",
      "78    79  Iris-versicolor  Iris-versicolor\n",
      "79    80  Iris-versicolor  Iris-versicolor\n",
      "80    81  Iris-versicolor  Iris-versicolor\n",
      "81    82  Iris-versicolor  Iris-versicolor\n",
      "82    83  Iris-versicolor  Iris-versicolor\n",
      "83    84  Iris-versicolor  Iris-versicolor\n",
      "84    85  Iris-versicolor  Iris-versicolor\n",
      "85    86  Iris-versicolor  Iris-versicolor\n",
      "86    87  Iris-versicolor  Iris-versicolor\n",
      "87    88  Iris-versicolor  Iris-versicolor\n",
      "88    89  Iris-versicolor  Iris-versicolor\n",
      "89    90  Iris-versicolor  Iris-versicolor\n",
      "90    91  Iris-versicolor  Iris-versicolor\n",
      "91    92  Iris-versicolor  Iris-versicolor\n",
      "92    93  Iris-versicolor  Iris-versicolor\n",
      "93    94  Iris-versicolor  Iris-versicolor\n",
      "94    95  Iris-versicolor  Iris-versicolor\n",
      "95    96  Iris-versicolor  Iris-versicolor\n",
      "96    97  Iris-versicolor  Iris-versicolor\n",
      "97    98  Iris-versicolor  Iris-versicolor\n",
      "98    99  Iris-versicolor  Iris-versicolor\n",
      "99   100  Iris-versicolor  Iris-versicolor\n",
      "100  101   Iris-virginica   Iris-virginica\n",
      "101  102   Iris-virginica   Iris-virginica\n",
      "102  103   Iris-virginica   Iris-virginica\n",
      "103  104   Iris-virginica   Iris-virginica\n",
      "104  105   Iris-virginica   Iris-virginica\n",
      "105  106   Iris-virginica   Iris-virginica\n",
      "106  107   Iris-virginica  Iris-versicolor\n",
      "107  108   Iris-virginica   Iris-virginica\n",
      "108  109   Iris-virginica   Iris-virginica\n",
      "109  110   Iris-virginica   Iris-virginica\n",
      "110  111   Iris-virginica   Iris-virginica\n",
      "111  112   Iris-virginica   Iris-virginica\n",
      "112  113   Iris-virginica   Iris-virginica\n",
      "113  114   Iris-virginica   Iris-virginica\n",
      "114  115   Iris-virginica   Iris-virginica\n",
      "115  116   Iris-virginica   Iris-virginica\n",
      "116  117   Iris-virginica   Iris-virginica\n",
      "117  118   Iris-virginica   Iris-virginica\n",
      "118  119   Iris-virginica   Iris-virginica\n",
      "119  120   Iris-virginica  Iris-versicolor\n",
      "120  121   Iris-virginica   Iris-virginica\n",
      "121  122   Iris-virginica   Iris-virginica\n",
      "122  123   Iris-virginica   Iris-virginica\n",
      "123  124   Iris-virginica   Iris-virginica\n",
      "124  125   Iris-virginica   Iris-virginica\n",
      "125  126   Iris-virginica   Iris-virginica\n",
      "126  127   Iris-virginica   Iris-virginica\n",
      "127  128   Iris-virginica   Iris-virginica\n",
      "128  129   Iris-virginica   Iris-virginica\n",
      "129  130   Iris-virginica   Iris-virginica\n",
      "130  131   Iris-virginica   Iris-virginica\n",
      "131  132   Iris-virginica   Iris-virginica\n",
      "132  133   Iris-virginica   Iris-virginica\n",
      "133  134   Iris-virginica  Iris-versicolor\n",
      "134  135   Iris-virginica  Iris-versicolor\n",
      "135  136   Iris-virginica   Iris-virginica\n",
      "136  137   Iris-virginica   Iris-virginica\n",
      "137  138   Iris-virginica   Iris-virginica\n",
      "138  139   Iris-virginica   Iris-virginica\n",
      "139  140   Iris-virginica   Iris-virginica\n",
      "140  141   Iris-virginica   Iris-virginica\n",
      "141  142   Iris-virginica   Iris-virginica\n",
      "142  143   Iris-virginica   Iris-virginica\n",
      "143  144   Iris-virginica   Iris-virginica\n",
      "144  145   Iris-virginica   Iris-virginica\n",
      "145  146   Iris-virginica   Iris-virginica\n",
      "146  147   Iris-virginica   Iris-virginica\n",
      "147  148   Iris-virginica   Iris-virginica\n",
      "148  149   Iris-virginica   Iris-virginica\n",
      "149  150   Iris-virginica   Iris-virginica\n",
      "\n",
      "=== Akurasi ===\n",
      "Akurasi: 0.97\n",
      "\n",
      "=== Laporan Klasifikasi ===\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        50\n",
      "Iris-versicolor       0.92      0.98      0.95        50\n",
      " Iris-virginica       0.98      0.92      0.95        50\n",
      "\n",
      "       accuracy                           0.97       150\n",
      "      macro avg       0.97      0.97      0.97       150\n",
      "   weighted avg       0.97      0.97      0.97       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load both files\n",
    "data_iris = pd.read_excel(\"data_iris_kategori_lengkap.xlsx\")\n",
    "class_asli = pd.read_excel(\"class.xlsx\")\n",
    "\n",
    "# Gabungkan data kategorikal dengan kelas asli berdasarkan 'id'\n",
    "data_gabungan = pd.merge(data_iris, class_asli[['id', 'class']], on='id')\n",
    "\n",
    "# Encode fitur kategorikal (A, B, dst.) ke numerik\n",
    "fitur_kategori = ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
    "for kolom in fitur_kategori:\n",
    "    encoder = LabelEncoder()\n",
    "    data_gabungan[kolom] = encoder.fit_transform(data_gabungan[kolom])\n",
    "\n",
    "# Encode label kelas\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data_gabungan['class'])\n",
    "X = data_gabungan[fitur_kategori]\n",
    "\n",
    "# Model Naive Bayes\n",
    "model = CategoricalNB()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Buat DataFrame hasil prediksi vs kelas asli\n",
    "hasil_prediksi = data_gabungan[['id']].copy()\n",
    "hasil_prediksi['kelas_asli'] = label_encoder.inverse_transform(y)\n",
    "hasil_prediksi['kelas_prediksi'] = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Simpan ke Excel\n",
    "output_path = \"naive_bayes.xlsx\"\n",
    "hasil_prediksi.to_excel(output_path, index=False)\n",
    "\n",
    "# Evaluasi hasil prediksi\n",
    "akurasi = accuracy_score(y, y_pred)\n",
    "laporan_klasifikasi = classification_report(y, y_pred, target_names=label_encoder.classes_)\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(\"\\n=== Hasil Prediksi Kelas ===\")\n",
    "print(hasil_prediksi)\n",
    "\n",
    "print(\"\\n=== Akurasi ===\")\n",
    "print(f\"Akurasi: {akurasi:.2f}\")\n",
    "\n",
    "print(\"\\n=== Laporan Klasifikasi ===\")\n",
    "print(laporan_klasifikasi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de60707",
   "metadata": {},
   "source": [
    "## Klasifikasi Naive Bayes Data Tanpa Diskritisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd80070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perbandingan Kelas Aktual dan Kelas Prediksi:\n",
      "    True Class Predicted Class\n",
      "0  Iris-setosa     Iris-setosa\n",
      "1  Iris-setosa     Iris-setosa\n",
      "2  Iris-setosa     Iris-setosa\n",
      "3  Iris-setosa     Iris-setosa\n",
      "4  Iris-setosa     Iris-setosa\n",
      "\n",
      "Akurasi: 0.9600\n",
      "\n",
      "Matriks Konfusi:\n",
      "[[50  0  0]\n",
      " [ 0 47  3]\n",
      " [ 0  3 47]]\n",
      "\n",
      "Laporan Klasifikasi:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        50\n",
      "Iris-versicolor       0.94      0.94      0.94        50\n",
      " Iris-virginica       0.94      0.94      0.94        50\n",
      "\n",
      "       accuracy                           0.96       150\n",
      "      macro avg       0.96      0.96      0.96       150\n",
      "   weighted avg       0.96      0.96      0.96       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Memuat dataset\n",
    "try:\n",
    "    df_iris = pd.read_excel('data_iris.xlsx')\n",
    "    df_class = pd.read_excel('class.xlsx')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading file: {e}. Pastikan file berada di direktori yang sama.\")\n",
    "    exit()\n",
    "\n",
    "# Menyiapkan data\n",
    "# Fitur (X) diambil dari df_iris, mengecualikan kolom 'id'\n",
    "X = df_iris.drop('id', axis=1)\n",
    "\n",
    "# Label sebenarnya (y_true) diambil dari kolom 'class' di df_class\n",
    "y_true = df_class['class']\n",
    "\n",
    "# Memastikan jumlah baris di X dan y_true cocok\n",
    "if X.shape[0] != y_true.shape[0]:\n",
    "    print(\"Error: Jumlah baris pada fitur dan variabel target sebenarnya tidak cocok.\")\n",
    "    exit()\n",
    "\n",
    "# Menginisialisasi model Gaussian Naive Bayes\n",
    "model = GaussianNB()\n",
    "\n",
    "# Melatih model menggunakan fitur dari df_iris dan label sebenarnya dari df_class\n",
    "model.fit(X, y_true)\n",
    "\n",
    "# Membuat prediksi pada fitur yang sama\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Membandingkan prediksi dengan kelas aktual (y_true)\n",
    "comparison_df = pd.DataFrame({'True Class': y_true, 'Predicted Class': y_pred})\n",
    "print(\"\\nPerbandingan Kelas Aktual dan Kelas Prediksi:\")\n",
    "print(comparison_df.head())\n",
    "\n",
    "# Mengevaluasi model\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nAkurasi: {accuracy:.4f}\")\n",
    "print(\"\\nMatriks Konfusi:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nLaporan Klasifikasi:\")\n",
    "print(class_report)\n",
    "\n",
    "comparison_df.to_excel('naive_bayes_classification_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8d1fa",
   "metadata": {},
   "source": [
    "## Klasifikasi Decision Tree Data Diskrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1204b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Akurasi Model Decision Tree (Data Diskritisasi): 0.9800\n",
      "\n",
      "Matriks Konfusi:\n",
      "[[50  0  0]\n",
      " [ 0 49  1]\n",
      " [ 0  2 48]]\n",
      "\n",
      "Laporan Klasifikasi:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        50\n",
      "Iris-versicolor       0.96      0.98      0.97        50\n",
      " Iris-virginica       0.98      0.96      0.97        50\n",
      "\n",
      "       accuracy                           0.98       150\n",
      "      macro avg       0.98      0.98      0.98       150\n",
      "   weighted avg       0.98      0.98      0.98       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split # Meskipun tidak digunakan untuk split di sini, ini adalah praktik baik\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# --- 1. Memuat data yang sudah didiskritisasi ---\n",
    "try:\n",
    "    df_discretized = pd.read_excel('data_iris_kategori_lengkap.xlsx')\n",
    "    df_true_class = pd.read_excel('class.xlsx')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading file: {e}. Pastikan file berada di direktori yang sama.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Menyiapkan data ---\n",
    "categorical_features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "X_categorical = df_discretized[categorical_features]\n",
    "\n",
    "# Variabel target (y) dari file kelas aktual\n",
    "y = df_true_class['class']\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X_categorical)\n",
    "\n",
    "feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "X_df_encoded = pd.DataFrame(X_encoded, columns=feature_names)\n",
    "\n",
    "if X_df_encoded.shape[0] != y.shape[0]:\n",
    "    print(\"Error: Jumlah baris pada fitur yang di-encode dan variabel target tidak cocok.\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Melatih pengklasifikasi Decision Tree ---\n",
    "# random_state digunakan untuk reproduksibilitas hasil\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Melatih model\n",
    "model.fit(X_df_encoded, y)\n",
    "\n",
    "# --- 4. Membuat prediksi ---\n",
    "y_pred = model.predict(X_df_encoded)\n",
    "\n",
    "# --- 5. Mengevaluasi model ---\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "class_report = classification_report(y, y_pred)\n",
    "\n",
    "print(f\"\\nAkurasi Model Decision Tree (Data Diskritisasi): {accuracy:.4f}\")\n",
    "print(\"\\nMatriks Konfusi:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nLaporan Klasifikasi:\")\n",
    "print(class_report)\n",
    "\n",
    "# Secara opsional, simpan perbandingan kelas aktual dan prediksi ke file CSV\n",
    "comparison_df_dt = pd.DataFrame({'True Class': y, 'Predicted Class': y_pred})\n",
    "comparison_df_dt.to_excel('decision_tree_discretized_classification_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c324f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          True Class  Predicted Class\n",
      "0        Iris-setosa      Iris-setosa\n",
      "1        Iris-setosa      Iris-setosa\n",
      "2        Iris-setosa      Iris-setosa\n",
      "3        Iris-setosa      Iris-setosa\n",
      "4        Iris-setosa      Iris-setosa\n",
      "5        Iris-setosa      Iris-setosa\n",
      "6        Iris-setosa      Iris-setosa\n",
      "7        Iris-setosa      Iris-setosa\n",
      "8        Iris-setosa      Iris-setosa\n",
      "9        Iris-setosa      Iris-setosa\n",
      "10       Iris-setosa      Iris-setosa\n",
      "11       Iris-setosa      Iris-setosa\n",
      "12       Iris-setosa      Iris-setosa\n",
      "13       Iris-setosa      Iris-setosa\n",
      "14       Iris-setosa      Iris-setosa\n",
      "15       Iris-setosa      Iris-setosa\n",
      "16       Iris-setosa      Iris-setosa\n",
      "17       Iris-setosa      Iris-setosa\n",
      "18       Iris-setosa      Iris-setosa\n",
      "19       Iris-setosa      Iris-setosa\n",
      "20       Iris-setosa      Iris-setosa\n",
      "21       Iris-setosa      Iris-setosa\n",
      "22       Iris-setosa      Iris-setosa\n",
      "23       Iris-setosa      Iris-setosa\n",
      "24       Iris-setosa      Iris-setosa\n",
      "25       Iris-setosa      Iris-setosa\n",
      "26       Iris-setosa      Iris-setosa\n",
      "27       Iris-setosa      Iris-setosa\n",
      "28       Iris-setosa      Iris-setosa\n",
      "29       Iris-setosa      Iris-setosa\n",
      "30       Iris-setosa      Iris-setosa\n",
      "31       Iris-setosa      Iris-setosa\n",
      "32       Iris-setosa      Iris-setosa\n",
      "33       Iris-setosa      Iris-setosa\n",
      "34       Iris-setosa      Iris-setosa\n",
      "35       Iris-setosa      Iris-setosa\n",
      "36       Iris-setosa      Iris-setosa\n",
      "37       Iris-setosa      Iris-setosa\n",
      "38       Iris-setosa      Iris-setosa\n",
      "39       Iris-setosa      Iris-setosa\n",
      "40       Iris-setosa      Iris-setosa\n",
      "41       Iris-setosa      Iris-setosa\n",
      "42       Iris-setosa      Iris-setosa\n",
      "43       Iris-setosa      Iris-setosa\n",
      "44       Iris-setosa      Iris-setosa\n",
      "45       Iris-setosa      Iris-setosa\n",
      "46       Iris-setosa      Iris-setosa\n",
      "47       Iris-setosa      Iris-setosa\n",
      "48       Iris-setosa      Iris-setosa\n",
      "49       Iris-setosa      Iris-setosa\n",
      "50   Iris-versicolor  Iris-versicolor\n",
      "51   Iris-versicolor  Iris-versicolor\n",
      "52   Iris-versicolor  Iris-versicolor\n",
      "53   Iris-versicolor  Iris-versicolor\n",
      "54   Iris-versicolor  Iris-versicolor\n",
      "55   Iris-versicolor  Iris-versicolor\n",
      "56   Iris-versicolor  Iris-versicolor\n",
      "57   Iris-versicolor  Iris-versicolor\n",
      "58   Iris-versicolor  Iris-versicolor\n",
      "59   Iris-versicolor  Iris-versicolor\n",
      "60   Iris-versicolor  Iris-versicolor\n",
      "61   Iris-versicolor  Iris-versicolor\n",
      "62   Iris-versicolor  Iris-versicolor\n",
      "63   Iris-versicolor  Iris-versicolor\n",
      "64   Iris-versicolor  Iris-versicolor\n",
      "65   Iris-versicolor  Iris-versicolor\n",
      "66   Iris-versicolor  Iris-versicolor\n",
      "67   Iris-versicolor  Iris-versicolor\n",
      "68   Iris-versicolor  Iris-versicolor\n",
      "69   Iris-versicolor  Iris-versicolor\n",
      "70   Iris-versicolor   Iris-virginica\n",
      "71   Iris-versicolor  Iris-versicolor\n",
      "72   Iris-versicolor  Iris-versicolor\n",
      "73   Iris-versicolor  Iris-versicolor\n",
      "74   Iris-versicolor  Iris-versicolor\n",
      "75   Iris-versicolor  Iris-versicolor\n",
      "76   Iris-versicolor  Iris-versicolor\n",
      "77   Iris-versicolor  Iris-versicolor\n",
      "78   Iris-versicolor  Iris-versicolor\n",
      "79   Iris-versicolor  Iris-versicolor\n",
      "80   Iris-versicolor  Iris-versicolor\n",
      "81   Iris-versicolor  Iris-versicolor\n",
      "82   Iris-versicolor  Iris-versicolor\n",
      "83   Iris-versicolor  Iris-versicolor\n",
      "84   Iris-versicolor  Iris-versicolor\n",
      "85   Iris-versicolor  Iris-versicolor\n",
      "86   Iris-versicolor  Iris-versicolor\n",
      "87   Iris-versicolor  Iris-versicolor\n",
      "88   Iris-versicolor  Iris-versicolor\n",
      "89   Iris-versicolor  Iris-versicolor\n",
      "90   Iris-versicolor  Iris-versicolor\n",
      "91   Iris-versicolor  Iris-versicolor\n",
      "92   Iris-versicolor  Iris-versicolor\n",
      "93   Iris-versicolor  Iris-versicolor\n",
      "94   Iris-versicolor  Iris-versicolor\n",
      "95   Iris-versicolor  Iris-versicolor\n",
      "96   Iris-versicolor  Iris-versicolor\n",
      "97   Iris-versicolor  Iris-versicolor\n",
      "98   Iris-versicolor  Iris-versicolor\n",
      "99   Iris-versicolor  Iris-versicolor\n",
      "100   Iris-virginica   Iris-virginica\n",
      "101   Iris-virginica   Iris-virginica\n",
      "102   Iris-virginica   Iris-virginica\n",
      "103   Iris-virginica   Iris-virginica\n",
      "104   Iris-virginica   Iris-virginica\n",
      "105   Iris-virginica   Iris-virginica\n",
      "106   Iris-virginica   Iris-virginica\n",
      "107   Iris-virginica   Iris-virginica\n",
      "108   Iris-virginica   Iris-virginica\n",
      "109   Iris-virginica   Iris-virginica\n",
      "110   Iris-virginica   Iris-virginica\n",
      "111   Iris-virginica   Iris-virginica\n",
      "112   Iris-virginica   Iris-virginica\n",
      "113   Iris-virginica   Iris-virginica\n",
      "114   Iris-virginica   Iris-virginica\n",
      "115   Iris-virginica   Iris-virginica\n",
      "116   Iris-virginica   Iris-virginica\n",
      "117   Iris-virginica   Iris-virginica\n",
      "118   Iris-virginica   Iris-virginica\n",
      "119   Iris-virginica  Iris-versicolor\n",
      "120   Iris-virginica   Iris-virginica\n",
      "121   Iris-virginica   Iris-virginica\n",
      "122   Iris-virginica   Iris-virginica\n",
      "123   Iris-virginica   Iris-virginica\n",
      "124   Iris-virginica   Iris-virginica\n",
      "125   Iris-virginica   Iris-virginica\n",
      "126   Iris-virginica   Iris-virginica\n",
      "127   Iris-virginica   Iris-virginica\n",
      "128   Iris-virginica   Iris-virginica\n",
      "129   Iris-virginica   Iris-virginica\n",
      "130   Iris-virginica   Iris-virginica\n",
      "131   Iris-virginica   Iris-virginica\n",
      "132   Iris-virginica   Iris-virginica\n",
      "133   Iris-virginica  Iris-versicolor\n",
      "134   Iris-virginica   Iris-virginica\n",
      "135   Iris-virginica   Iris-virginica\n",
      "136   Iris-virginica   Iris-virginica\n",
      "137   Iris-virginica   Iris-virginica\n",
      "138   Iris-virginica   Iris-virginica\n",
      "139   Iris-virginica   Iris-virginica\n",
      "140   Iris-virginica   Iris-virginica\n",
      "141   Iris-virginica   Iris-virginica\n",
      "142   Iris-virginica   Iris-virginica\n",
      "143   Iris-virginica   Iris-virginica\n",
      "144   Iris-virginica   Iris-virginica\n",
      "145   Iris-virginica   Iris-virginica\n",
      "146   Iris-virginica   Iris-virginica\n",
      "147   Iris-virginica   Iris-virginica\n",
      "148   Iris-virginica   Iris-virginica\n",
      "149   Iris-virginica   Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_excel('decision_tree_discretized_classification_results.xlsx')\n",
    "# Tampilkan semua baris\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520f6c94",
   "metadata": {},
   "source": [
    "## Klasifikasi Decision Tree Data Tanpa Diskritisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d3996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Akurasi Model Decision Tree (Data Iris Asli): 1.0000\n",
      "\n",
      "Matriks Konfusi:\n",
      "[[50  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0  0 50]]\n",
      "\n",
      "Laporan Klasifikasi:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        50\n",
      "Iris-versicolor       1.00      1.00      1.00        50\n",
      " Iris-virginica       1.00      1.00      1.00        50\n",
      "\n",
      "       accuracy                           1.00       150\n",
      "      macro avg       1.00      1.00      1.00       150\n",
      "   weighted avg       1.00      1.00      1.00       150\n",
      "\n",
      "\n",
      "Hasil klasifikasi Decision Tree pada data Iris asli disimpan ke 'decision_tree_original_iris_classification_results.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split # Termasuk untuk praktik baik\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. Memuat data Iris asli ---\n",
    "try:\n",
    "    df_iris_original = pd.read_excel('data_iris.xlsx')\n",
    "    df_true_class = pd.read_excel('class.xlsx')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading file: {e}. Pastikan file berada di direktori yang sama.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Menyiapkan data ---\n",
    "# Fitur (X) dari data Iris asli, mengecualikan kolom 'id'\n",
    "features = ['petal_length', 'petal_width', 'sepal_length', 'sepal_width']\n",
    "X = df_iris_original[features]\n",
    "\n",
    "# Variabel target (y) dari file kelas aktual\n",
    "y = df_true_class['class']\n",
    "\n",
    "# Memastikan jumlah sampel di X dan y cocok\n",
    "if X.shape[0] != y.shape[0]:\n",
    "    print(\"Error: Jumlah baris pada fitur dan variabel target tidak cocok.\")\n",
    "    exit()\n",
    "\n",
    "# Untuk tujuan demonstrasi ini, kita akan melatih dan mengevaluasi pada seluruh dataset.\n",
    "# Dalam skenario dunia nyata, sangat disarankan untuk menggunakan train_test_split\n",
    "# untuk membagi data menjadi set pelatihan dan pengujian guna mendapatkan evaluasi model yang lebih realistis.\n",
    "# Contoh penggunaan train_test_split:\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# --- 3. Melatih pengklasifikasi Decision Tree ---\n",
    "# random_state digunakan untuk reproduksibilitas hasil\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Melatih model\n",
    "model.fit(X, y)\n",
    "\n",
    "# --- 4. Membuat prediksi ---\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# --- 5. Mengevaluasi model ---\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "class_report = classification_report(y, y_pred)\n",
    "\n",
    "print(f\"\\nAkurasi Model Decision Tree (Data Iris Asli): {accuracy:.4f}\")\n",
    "print(\"\\nMatriks Konfusi:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nLaporan Klasifikasi:\")\n",
    "print(class_report)\n",
    "\n",
    "comparison_df_dt_original = pd.DataFrame({'True Class': y, 'Predicted Class': y_pred})\n",
    "comparison_df_dt_original.to_excel('decision_tree_original_iris_classification_results.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ee1f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          True Class  Predicted Class\n",
      "0        Iris-setosa      Iris-setosa\n",
      "1        Iris-setosa      Iris-setosa\n",
      "2        Iris-setosa      Iris-setosa\n",
      "3        Iris-setosa      Iris-setosa\n",
      "4        Iris-setosa      Iris-setosa\n",
      "5        Iris-setosa      Iris-setosa\n",
      "6        Iris-setosa      Iris-setosa\n",
      "7        Iris-setosa      Iris-setosa\n",
      "8        Iris-setosa      Iris-setosa\n",
      "9        Iris-setosa      Iris-setosa\n",
      "10       Iris-setosa      Iris-setosa\n",
      "11       Iris-setosa      Iris-setosa\n",
      "12       Iris-setosa      Iris-setosa\n",
      "13       Iris-setosa      Iris-setosa\n",
      "14       Iris-setosa      Iris-setosa\n",
      "15       Iris-setosa      Iris-setosa\n",
      "16       Iris-setosa      Iris-setosa\n",
      "17       Iris-setosa      Iris-setosa\n",
      "18       Iris-setosa      Iris-setosa\n",
      "19       Iris-setosa      Iris-setosa\n",
      "20       Iris-setosa      Iris-setosa\n",
      "21       Iris-setosa      Iris-setosa\n",
      "22       Iris-setosa      Iris-setosa\n",
      "23       Iris-setosa      Iris-setosa\n",
      "24       Iris-setosa      Iris-setosa\n",
      "25       Iris-setosa      Iris-setosa\n",
      "26       Iris-setosa      Iris-setosa\n",
      "27       Iris-setosa      Iris-setosa\n",
      "28       Iris-setosa      Iris-setosa\n",
      "29       Iris-setosa      Iris-setosa\n",
      "30       Iris-setosa      Iris-setosa\n",
      "31       Iris-setosa      Iris-setosa\n",
      "32       Iris-setosa      Iris-setosa\n",
      "33       Iris-setosa      Iris-setosa\n",
      "34       Iris-setosa      Iris-setosa\n",
      "35       Iris-setosa      Iris-setosa\n",
      "36       Iris-setosa      Iris-setosa\n",
      "37       Iris-setosa      Iris-setosa\n",
      "38       Iris-setosa      Iris-setosa\n",
      "39       Iris-setosa      Iris-setosa\n",
      "40       Iris-setosa      Iris-setosa\n",
      "41       Iris-setosa      Iris-setosa\n",
      "42       Iris-setosa      Iris-setosa\n",
      "43       Iris-setosa      Iris-setosa\n",
      "44       Iris-setosa      Iris-setosa\n",
      "45       Iris-setosa      Iris-setosa\n",
      "46       Iris-setosa      Iris-setosa\n",
      "47       Iris-setosa      Iris-setosa\n",
      "48       Iris-setosa      Iris-setosa\n",
      "49       Iris-setosa      Iris-setosa\n",
      "50   Iris-versicolor  Iris-versicolor\n",
      "51   Iris-versicolor  Iris-versicolor\n",
      "52   Iris-versicolor  Iris-versicolor\n",
      "53   Iris-versicolor  Iris-versicolor\n",
      "54   Iris-versicolor  Iris-versicolor\n",
      "55   Iris-versicolor  Iris-versicolor\n",
      "56   Iris-versicolor  Iris-versicolor\n",
      "57   Iris-versicolor  Iris-versicolor\n",
      "58   Iris-versicolor  Iris-versicolor\n",
      "59   Iris-versicolor  Iris-versicolor\n",
      "60   Iris-versicolor  Iris-versicolor\n",
      "61   Iris-versicolor  Iris-versicolor\n",
      "62   Iris-versicolor  Iris-versicolor\n",
      "63   Iris-versicolor  Iris-versicolor\n",
      "64   Iris-versicolor  Iris-versicolor\n",
      "65   Iris-versicolor  Iris-versicolor\n",
      "66   Iris-versicolor  Iris-versicolor\n",
      "67   Iris-versicolor  Iris-versicolor\n",
      "68   Iris-versicolor  Iris-versicolor\n",
      "69   Iris-versicolor  Iris-versicolor\n",
      "70   Iris-versicolor  Iris-versicolor\n",
      "71   Iris-versicolor  Iris-versicolor\n",
      "72   Iris-versicolor  Iris-versicolor\n",
      "73   Iris-versicolor  Iris-versicolor\n",
      "74   Iris-versicolor  Iris-versicolor\n",
      "75   Iris-versicolor  Iris-versicolor\n",
      "76   Iris-versicolor  Iris-versicolor\n",
      "77   Iris-versicolor  Iris-versicolor\n",
      "78   Iris-versicolor  Iris-versicolor\n",
      "79   Iris-versicolor  Iris-versicolor\n",
      "80   Iris-versicolor  Iris-versicolor\n",
      "81   Iris-versicolor  Iris-versicolor\n",
      "82   Iris-versicolor  Iris-versicolor\n",
      "83   Iris-versicolor  Iris-versicolor\n",
      "84   Iris-versicolor  Iris-versicolor\n",
      "85   Iris-versicolor  Iris-versicolor\n",
      "86   Iris-versicolor  Iris-versicolor\n",
      "87   Iris-versicolor  Iris-versicolor\n",
      "88   Iris-versicolor  Iris-versicolor\n",
      "89   Iris-versicolor  Iris-versicolor\n",
      "90   Iris-versicolor  Iris-versicolor\n",
      "91   Iris-versicolor  Iris-versicolor\n",
      "92   Iris-versicolor  Iris-versicolor\n",
      "93   Iris-versicolor  Iris-versicolor\n",
      "94   Iris-versicolor  Iris-versicolor\n",
      "95   Iris-versicolor  Iris-versicolor\n",
      "96   Iris-versicolor  Iris-versicolor\n",
      "97   Iris-versicolor  Iris-versicolor\n",
      "98   Iris-versicolor  Iris-versicolor\n",
      "99   Iris-versicolor  Iris-versicolor\n",
      "100   Iris-virginica   Iris-virginica\n",
      "101   Iris-virginica   Iris-virginica\n",
      "102   Iris-virginica   Iris-virginica\n",
      "103   Iris-virginica   Iris-virginica\n",
      "104   Iris-virginica   Iris-virginica\n",
      "105   Iris-virginica   Iris-virginica\n",
      "106   Iris-virginica   Iris-virginica\n",
      "107   Iris-virginica   Iris-virginica\n",
      "108   Iris-virginica   Iris-virginica\n",
      "109   Iris-virginica   Iris-virginica\n",
      "110   Iris-virginica   Iris-virginica\n",
      "111   Iris-virginica   Iris-virginica\n",
      "112   Iris-virginica   Iris-virginica\n",
      "113   Iris-virginica   Iris-virginica\n",
      "114   Iris-virginica   Iris-virginica\n",
      "115   Iris-virginica   Iris-virginica\n",
      "116   Iris-virginica   Iris-virginica\n",
      "117   Iris-virginica   Iris-virginica\n",
      "118   Iris-virginica   Iris-virginica\n",
      "119   Iris-virginica   Iris-virginica\n",
      "120   Iris-virginica   Iris-virginica\n",
      "121   Iris-virginica   Iris-virginica\n",
      "122   Iris-virginica   Iris-virginica\n",
      "123   Iris-virginica   Iris-virginica\n",
      "124   Iris-virginica   Iris-virginica\n",
      "125   Iris-virginica   Iris-virginica\n",
      "126   Iris-virginica   Iris-virginica\n",
      "127   Iris-virginica   Iris-virginica\n",
      "128   Iris-virginica   Iris-virginica\n",
      "129   Iris-virginica   Iris-virginica\n",
      "130   Iris-virginica   Iris-virginica\n",
      "131   Iris-virginica   Iris-virginica\n",
      "132   Iris-virginica   Iris-virginica\n",
      "133   Iris-virginica   Iris-virginica\n",
      "134   Iris-virginica   Iris-virginica\n",
      "135   Iris-virginica   Iris-virginica\n",
      "136   Iris-virginica   Iris-virginica\n",
      "137   Iris-virginica   Iris-virginica\n",
      "138   Iris-virginica   Iris-virginica\n",
      "139   Iris-virginica   Iris-virginica\n",
      "140   Iris-virginica   Iris-virginica\n",
      "141   Iris-virginica   Iris-virginica\n",
      "142   Iris-virginica   Iris-virginica\n",
      "143   Iris-virginica   Iris-virginica\n",
      "144   Iris-virginica   Iris-virginica\n",
      "145   Iris-virginica   Iris-virginica\n",
      "146   Iris-virginica   Iris-virginica\n",
      "147   Iris-virginica   Iris-virginica\n",
      "148   Iris-virginica   Iris-virginica\n",
      "149   Iris-virginica   Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_excel('decision_tree_original_iris_classification_results.xlsx')\n",
    "\n",
    "# Tampilkan semua baris\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7ac4f",
   "metadata": {},
   "source": [
    "## Kesimpulan  \n",
    "$\n",
    "\\begin{array}{lcccc}\n",
    "\\hline\n",
    "\\textbf{Model} & \\textbf{Akurasi} \\\\\n",
    "\\hline\n",
    "\\text{Naive Bayes (diskritisasi)} & 0.97 \\\\\n",
    "\\text{Naive Bayes (iris-asli)} & 0.96 \\\\\n",
    "\\text{Decision Tree (diskritisasi)} & 0.98 \\\\\n",
    "\\text{Decision Tree (iris-asli)} & 1.00 \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$  \n",
    "\n",
    "Secara keseluruhan, Decision Tree menunjukkan kinerja yang lebih unggul dibandingkan Naive Bayes pada kedua jenis data.Pengolahan data (diskritisasi) memberikan dampak yang berbeda pada kedua model:\n",
    "\n",
    "* Pada Naive Bayes, proses diskritisasi justru meningkatkan kinerja model dari 0.96 menjadi 0.97. Ini menunjukkan bahwa model Naive Bayes dalam kasus ini bekerja lebih baik dengan fitur-fitur yang bersifat kategorikal (hasil diskritisasi).\n",
    "* Pada Decision Tree, proses diskritisasi sedikit menurunkan kinerja model dari 1.00 menjadi 0.98. Hal ini menandakan bahwa Decision Tree mampu memanfaatkan informasi dari data numerik kontinu pada set data Iris asli secara lebih efektif untuk mencapai hasil yang sempurna.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
