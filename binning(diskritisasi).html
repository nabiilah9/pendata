
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Binning (Diskritisasi) menggunakan K-Means Clustering &#8212; Penambangan Data</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'binning(diskritisasi)';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Implementasi Model Klasifikasi untuk Prediksi Tingkat Keparahan Penyakit Jantung Berdasarkan Data Medis" href="heart_disease.html" />
    <link rel="prev" title="Decision Tree" href="decisiontree.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/2.png" class="logo__image only-light" alt="Penambangan Data - Home"/>
    <img src="_static/2.png" class="logo__image only-dark pst-js-only" alt="Penambangan Data - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Penambangan Data
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data_understanding.html">Memahami Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="naive_bayes.html">Metode Klasifikasi Naive Bayes</a></li>
<li class="toctree-l1"><a class="reference internal" href="uts.html">UTS</a></li>
<li class="toctree-l1"><a class="reference internal" href="clustering.html">K-Means Clustering</a></li>

<li class="toctree-l1"><a class="reference internal" href="decisiontree.html">Decision Tree</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Binning (Diskritisasi) menggunakan K-Means Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="heart_disease.html">Implementasi Model Klasifikasi untuk Prediksi Tingkat Keparahan Penyakit Jantung Berdasarkan Data Medis</a></li>
<li class="toctree-l1"><a class="reference internal" href="uas.html">Prediksi Diagnosis Kanker Payudara</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fbinning(diskritisasi).html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/binning(diskritisasi).ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Binning (Diskritisasi) menggunakan K-Means Clustering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clusterisasi-dengan-k-means">Clusterisasi dengan K-Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cari-min-max-dan-centroid-dari-fitur-sepal-length">Cari Min Max dan Centroid dari fitur sepal length</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-diskritisasi-fitur-sepal-length">Hasil Diskritisasi fitur sepal length</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengganti-fitur-sepal-length-numeriks-ke-sepal-length-kategorikal">Mengganti fitur sepal_length(numeriks) ke sepal_length (kategorikal)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#melakukan-proses-diskritisasi-dengan-k-means-clustering-pada-fitur-lainya">Melakukan proses diskritisasi dengan K-means clustering pada fitur lainya</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menampilkan-semua-data-hasil-diskritisasi-setiap-fitur">Menampilkan semua data hasil diskritisasi setiap fitur</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-naive-bayes-data-diskrit">Klasifikasi Naive Bayes Data Diskrit</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-naive-bayes-data-tanpa-diskritisasi">Klasifikasi Naive Bayes Data Tanpa Diskritisasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-decision-tree-data-diskrit">Klasifikasi Decision Tree Data Diskrit</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-decision-tree-data-tanpa-diskritisasi">Klasifikasi Decision Tree Data Tanpa Diskritisasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">Kesimpulan</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="binning-diskritisasi-menggunakan-k-means-clustering">
<h1>Binning (Diskritisasi) menggunakan K-Means Clustering<a class="headerlink" href="#binning-diskritisasi-menggunakan-k-means-clustering" title="Link to this heading">#</a></h1>
<section id="clusterisasi-dengan-k-means">
<h2>Clusterisasi dengan K-Means<a class="headerlink" href="#clusterisasi-dengan-k-means" title="Link to this heading">#</a></h2>
<p>Clusterisasi dengan K-Means digunakan untuk mengelompokkan data pada fitur Sepal Length menjadi 4 kelompok (klaster) yaitu 0, 1, 2, 3, 4 berdasarkan tingkat kemiripan nilai. Proses ini dilakukan dengan cara mengelompokkan data yang memiliki nilai panjang sepal yang saling berdekatan ke dalam satu klaster yang sama. Nantinya setiap klaster yang terbentuk akan mewakili satu interval nilai.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">silhouette_score</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Baca data fitur dan label</span>
<span class="n">df_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;data_iris.xlsx&quot;</span><span class="p">)</span>   
<span class="n">df_class</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;class.xlsx&quot;</span><span class="p">)</span>          

<span class="c1"># Gabungkan data fitur dan label</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df_features</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="c1"># Ambil hanya kolom sepal_length</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">]]</span>

<span class="c1"># Normalisasi fitur</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="c1"># Clustering KMeans dengan 4 klaster</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">)</span>

<span class="c1"># Simpan hasil cluster ke dataframe</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Evaluasi</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah iterasi sampai konvergen: </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">n_iter_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Inertia (SSE): </span><span class="si">{</span><span class="n">kmeans</span><span class="o">.</span><span class="n">inertia_</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">sil_score</span> <span class="o">=</span> <span class="n">silhouette_score</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">,</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Silhouette Score: </span><span class="si">{</span><span class="n">sil_score</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Pemetaan cluster ke class mayoritas</span>
<span class="n">mapping</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;cluster&#39;</span><span class="p">)[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">mode</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">mapping</span><span class="p">)</span>

<span class="c1"># Hitung akurasi prediksi clustering terhadap label asli</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span>
<span class="n">acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Akurasi keseluruhan clustering terhadap label asli: </span><span class="si">{</span><span class="n">acc</span><span class="si">:</span><span class="s2">.4%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Tampilkan distribusi cluster per kelas</span>
<span class="n">dist</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">],</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class&#39;</span><span class="p">],</span> <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cluster&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Distribusi cluster per kelas:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dist</span><span class="p">)</span>

<span class="c1"># Simpan hasil ke Excel</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;clus_dis.xlsx&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Jika ingin tampilkan semua hasil</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="s1">&#39;cluster&#39;</span><span class="p">,</span> <span class="s1">&#39;predicted_class&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah iterasi sampai konvergen: 2
Inertia (SSE): 0.6416
Silhouette Score: 0.5920

Akurasi keseluruhan clustering terhadap label asli: 72.0000%

Distribusi cluster per kelas:
Cluster           0   1   2   3
Class                          
Iris-setosa      10   0  40   0
Iris-versicolor  29   0   5  16
Iris-virginica   10  12   1  27
               class  cluster  predicted_class
0        Iris-setosa        2      Iris-setosa
1        Iris-setosa        2      Iris-setosa
2        Iris-setosa        2      Iris-setosa
3        Iris-setosa        2      Iris-setosa
4        Iris-setosa        2      Iris-setosa
5        Iris-setosa        0  Iris-versicolor
6        Iris-setosa        2      Iris-setosa
7        Iris-setosa        2      Iris-setosa
8        Iris-setosa        2      Iris-setosa
9        Iris-setosa        2      Iris-setosa
10       Iris-setosa        0  Iris-versicolor
11       Iris-setosa        2      Iris-setosa
12       Iris-setosa        2      Iris-setosa
13       Iris-setosa        2      Iris-setosa
14       Iris-setosa        0  Iris-versicolor
15       Iris-setosa        0  Iris-versicolor
16       Iris-setosa        0  Iris-versicolor
17       Iris-setosa        2      Iris-setosa
18       Iris-setosa        0  Iris-versicolor
19       Iris-setosa        2      Iris-setosa
20       Iris-setosa        0  Iris-versicolor
21       Iris-setosa        2      Iris-setosa
22       Iris-setosa        2      Iris-setosa
23       Iris-setosa        2      Iris-setosa
24       Iris-setosa        2      Iris-setosa
25       Iris-setosa        2      Iris-setosa
26       Iris-setosa        2      Iris-setosa
27       Iris-setosa        2      Iris-setosa
28       Iris-setosa        2      Iris-setosa
29       Iris-setosa        2      Iris-setosa
30       Iris-setosa        2      Iris-setosa
31       Iris-setosa        0  Iris-versicolor
32       Iris-setosa        2      Iris-setosa
33       Iris-setosa        0  Iris-versicolor
34       Iris-setosa        2      Iris-setosa
35       Iris-setosa        2      Iris-setosa
36       Iris-setosa        0  Iris-versicolor
37       Iris-setosa        2      Iris-setosa
38       Iris-setosa        2      Iris-setosa
39       Iris-setosa        2      Iris-setosa
40       Iris-setosa        2      Iris-setosa
41       Iris-setosa        2      Iris-setosa
42       Iris-setosa        2      Iris-setosa
43       Iris-setosa        2      Iris-setosa
44       Iris-setosa        2      Iris-setosa
45       Iris-setosa        2      Iris-setosa
46       Iris-setosa        2      Iris-setosa
47       Iris-setosa        2      Iris-setosa
48       Iris-setosa        2      Iris-setosa
49       Iris-setosa        2      Iris-setosa
50   Iris-versicolor        3   Iris-virginica
51   Iris-versicolor        3   Iris-virginica
52   Iris-versicolor        3   Iris-virginica
53   Iris-versicolor        0  Iris-versicolor
54   Iris-versicolor        3   Iris-virginica
55   Iris-versicolor        0  Iris-versicolor
56   Iris-versicolor        3   Iris-virginica
57   Iris-versicolor        2      Iris-setosa
58   Iris-versicolor        3   Iris-virginica
59   Iris-versicolor        2      Iris-setosa
60   Iris-versicolor        2      Iris-setosa
61   Iris-versicolor        0  Iris-versicolor
62   Iris-versicolor        0  Iris-versicolor
63   Iris-versicolor        0  Iris-versicolor
64   Iris-versicolor        0  Iris-versicolor
65   Iris-versicolor        3   Iris-virginica
66   Iris-versicolor        0  Iris-versicolor
67   Iris-versicolor        0  Iris-versicolor
68   Iris-versicolor        3   Iris-virginica
69   Iris-versicolor        0  Iris-versicolor
70   Iris-versicolor        0  Iris-versicolor
71   Iris-versicolor        0  Iris-versicolor
72   Iris-versicolor        3   Iris-virginica
73   Iris-versicolor        0  Iris-versicolor
74   Iris-versicolor        3   Iris-virginica
75   Iris-versicolor        3   Iris-virginica
76   Iris-versicolor        3   Iris-virginica
77   Iris-versicolor        3   Iris-virginica
78   Iris-versicolor        0  Iris-versicolor
79   Iris-versicolor        0  Iris-versicolor
80   Iris-versicolor        0  Iris-versicolor
81   Iris-versicolor        0  Iris-versicolor
82   Iris-versicolor        0  Iris-versicolor
83   Iris-versicolor        0  Iris-versicolor
84   Iris-versicolor        0  Iris-versicolor
85   Iris-versicolor        0  Iris-versicolor
86   Iris-versicolor        3   Iris-virginica
87   Iris-versicolor        3   Iris-virginica
88   Iris-versicolor        0  Iris-versicolor
89   Iris-versicolor        0  Iris-versicolor
90   Iris-versicolor        0  Iris-versicolor
91   Iris-versicolor        0  Iris-versicolor
92   Iris-versicolor        0  Iris-versicolor
93   Iris-versicolor        2      Iris-setosa
94   Iris-versicolor        0  Iris-versicolor
95   Iris-versicolor        0  Iris-versicolor
96   Iris-versicolor        0  Iris-versicolor
97   Iris-versicolor        3   Iris-virginica
98   Iris-versicolor        2      Iris-setosa
99   Iris-versicolor        0  Iris-versicolor
100   Iris-virginica        3   Iris-virginica
101   Iris-virginica        0  Iris-versicolor
102   Iris-virginica        1   Iris-virginica
103   Iris-virginica        3   Iris-virginica
104   Iris-virginica        3   Iris-virginica
105   Iris-virginica        1   Iris-virginica
106   Iris-virginica        2      Iris-setosa
107   Iris-virginica        1   Iris-virginica
108   Iris-virginica        3   Iris-virginica
109   Iris-virginica        1   Iris-virginica
110   Iris-virginica        3   Iris-virginica
111   Iris-virginica        3   Iris-virginica
112   Iris-virginica        3   Iris-virginica
113   Iris-virginica        0  Iris-versicolor
114   Iris-virginica        0  Iris-versicolor
115   Iris-virginica        3   Iris-virginica
116   Iris-virginica        3   Iris-virginica
117   Iris-virginica        1   Iris-virginica
118   Iris-virginica        1   Iris-virginica
119   Iris-virginica        0  Iris-versicolor
120   Iris-virginica        3   Iris-virginica
121   Iris-virginica        0  Iris-versicolor
122   Iris-virginica        1   Iris-virginica
123   Iris-virginica        3   Iris-virginica
124   Iris-virginica        3   Iris-virginica
125   Iris-virginica        1   Iris-virginica
126   Iris-virginica        3   Iris-virginica
127   Iris-virginica        0  Iris-versicolor
128   Iris-virginica        3   Iris-virginica
129   Iris-virginica        1   Iris-virginica
130   Iris-virginica        1   Iris-virginica
131   Iris-virginica        1   Iris-virginica
132   Iris-virginica        3   Iris-virginica
133   Iris-virginica        3   Iris-virginica
134   Iris-virginica        0  Iris-versicolor
135   Iris-virginica        1   Iris-virginica
136   Iris-virginica        3   Iris-virginica
137   Iris-virginica        3   Iris-virginica
138   Iris-virginica        0  Iris-versicolor
139   Iris-virginica        3   Iris-virginica
140   Iris-virginica        3   Iris-virginica
141   Iris-virginica        3   Iris-virginica
142   Iris-virginica        0  Iris-versicolor
143   Iris-virginica        3   Iris-virginica
144   Iris-virginica        3   Iris-virginica
145   Iris-virginica        3   Iris-virginica
146   Iris-virginica        3   Iris-virginica
147   Iris-virginica        3   Iris-virginica
148   Iris-virginica        3   Iris-virginica
149   Iris-virginica        0  Iris-versicolor
</pre></div>
</div>
</div>
</div>
</section>
<section id="cari-min-max-dan-centroid-dari-fitur-sepal-length">
<h2>Cari Min Max dan Centroid dari fitur sepal length<a class="headerlink" href="#cari-min-max-dan-centroid-dari-fitur-sepal-length" title="Link to this heading">#</a></h2>
<p>Pada tahap ini diperoleh informasi statistik yang mencakup nilai minimum (min), maksimum (max), dan centroid (nilai rata-rata) dari masing-masing cluster yang terbentuk. Statistik min dan max yang diperoleh dari hasil clustering ini nantinya dapat digunakan sebagai batas interval dalam proses diskritisasi fitur Sepal Length, sedangkan centroid dapat dimanfaatkan sebagai representasi numerik atau label diskrit dari masing-masing interval. Setiap data Sepal Length yang berada dalam suatu rentang (min hingga max) akan diberi label sesuai klaster tempatnya berada, menjadikan fitur tersebut tidak lagi berbentuk kontinu, melainkan sudah dalam bentuk kategori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Contoh Data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;clus_dis.xlsx&quot;</span><span class="p">)</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">]]</span>

<span class="c1"># Normalisasi</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="c1"># KMeans Clustering</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">)</span>

<span class="c1"># Tambahkan hasil cluster ke data</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Ambil centroid dari hasil clustering (dalam skala normalisasi)</span>
<span class="n">centroids_scaled</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">cluster_centers_</span>

<span class="c1"># Konversi centroid ke skala asli</span>
<span class="n">centroids_original</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">centroids_scaled</span><span class="p">)</span>

<span class="c1"># Hitung min, max, dan centroid per klaster</span>
<span class="n">cluster_stats</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;cluster&#39;</span><span class="p">)[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">cluster_stats</span><span class="p">[</span><span class="s1">&#39;centroid&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">centroids_original</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

<span class="c1"># Tampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Statistik Sepal Length per Cluster:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cluster_stats</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Statistik Sepal Length per Cluster:
         min  max  centroid
cluster                    
0        5.4  6.1  5.734694
1        7.1  7.9  7.475000
2        4.3  5.3  4.895652
3        6.2  7.0  6.525581
</pre></div>
</div>
</div>
</div>
<p>Output tersebut adalah statistik dari fitur Sepal Length yang telah dikelompokkan ke dalam 4 klaster menggunakan KMeans Clustering. Untuk masing-masing klaster ditampilkan:</p>
<ul class="simple">
<li><p>min: Nilai terkecil dari Sepal Length dalam klaster tersebut. Bisa digunakan sebagai batas bawah interval.</p></li>
<li><p>max: Nilai terbesar dari Sepal Length dalam klaster tersebut. Bisa digunakan sebagai batas atas interval.</p></li>
<li><p>centroid: Nilai rata-rata (mean) dari Sepal Length dalam klaster tersebut, yang merupakan pusat dari klaster (hasil centroids_ dari KMeans).</p></li>
</ul>
<p>Statistik min max dapat digunakan sebagai interval untuk diskritisasi pada fitur sepal_length</p>
</section>
<section id="hasil-diskritisasi-fitur-sepal-length">
<h2>Hasil Diskritisasi fitur sepal length<a class="headerlink" href="#hasil-diskritisasi-fitur-sepal-length" title="Link to this heading">#</a></h2>
<p>Pada tahap ini dilakukan proses diskritisasi terhadap fitur numerik sepal_length berdasarkan hasil klasterisasi sebelumnya. Setiap data telah dikelompokkan ke dalam klaster menggunakan algoritma K-Means, dan hasil klaster tersebut kemudian digunakan untuk memberi label diskrit pada nilai sepal_length. Contoh, pada baris pertama, nilai sepal_length_original adalah 5.1 dan termasuk dalam klaster 2 berdasarkan rentang min max, sehingga label diskritisasi menjadi ‘C’. Dengan pendekatan ini, fitur sepal_length yang semula berupa nilai kontinu kini telah dikonversi menjadi fitur kategori.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pemetaan cluster ke label huruf</span>
<span class="n">cluster_to_label</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;D&#39;</span>
<span class="p">}</span>

<span class="c1"># Salin kolom sepal_length asli ke kolom baru (agar data numerik tetap tersimpan)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;sepal_length_original&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">]</span>

<span class="c1"># Gantikan nilai sepal_length dengan huruf berdasarkan klaster</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">cluster_to_label</span><span class="p">)</span>

<span class="c1"># Tampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">[[</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_length_original&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     cluster sepal_length  sepal_length_original
0          2            C                    5.1
1          2            C                    4.9
2          2            C                    4.7
3          2            C                    4.6
4          2            C                    5.0
5          0            A                    5.4
6          2            C                    4.6
7          2            C                    5.0
8          2            C                    4.4
9          2            C                    4.9
10         0            A                    5.4
11         2            C                    4.8
12         2            C                    4.8
13         2            C                    4.3
14         0            A                    5.8
15         0            A                    5.7
16         0            A                    5.4
17         2            C                    5.1
18         0            A                    5.7
19         2            C                    5.1
20         0            A                    5.4
21         2            C                    5.1
22         2            C                    4.6
23         2            C                    5.1
24         2            C                    4.8
25         2            C                    5.0
26         2            C                    5.0
27         2            C                    5.2
28         2            C                    5.2
29         2            C                    4.7
30         2            C                    4.8
31         0            A                    5.4
32         2            C                    5.2
33         0            A                    5.5
34         2            C                    4.9
35         2            C                    5.0
36         0            A                    5.5
37         2            C                    4.9
38         2            C                    4.4
39         2            C                    5.1
40         2            C                    5.0
41         2            C                    4.5
42         2            C                    4.4
43         2            C                    5.0
44         2            C                    5.1
45         2            C                    4.8
46         2            C                    5.1
47         2            C                    4.6
48         2            C                    5.3
49         2            C                    5.0
50         3            D                    7.0
51         3            D                    6.4
52         3            D                    6.9
53         0            A                    5.5
54         3            D                    6.5
55         0            A                    5.7
56         3            D                    6.3
57         2            C                    4.9
58         3            D                    6.6
59         2            C                    5.2
60         2            C                    5.0
61         0            A                    5.9
62         0            A                    6.0
63         0            A                    6.1
64         0            A                    5.6
65         3            D                    6.7
66         0            A                    5.6
67         0            A                    5.8
68         3            D                    6.2
69         0            A                    5.6
70         0            A                    5.9
71         0            A                    6.1
72         3            D                    6.3
73         0            A                    6.1
74         3            D                    6.4
75         3            D                    6.6
76         3            D                    6.8
77         3            D                    6.7
78         0            A                    6.0
79         0            A                    5.7
80         0            A                    5.5
81         0            A                    5.5
82         0            A                    5.8
83         0            A                    6.0
84         0            A                    5.4
85         0            A                    6.0
86         3            D                    6.7
87         3            D                    6.3
88         0            A                    5.6
89         0            A                    5.5
90         0            A                    5.5
91         0            A                    6.1
92         0            A                    5.8
93         2            C                    5.0
94         0            A                    5.6
95         0            A                    5.7
96         0            A                    5.7
97         3            D                    6.2
98         2            C                    5.1
99         0            A                    5.7
100        3            D                    6.3
101        0            A                    5.8
102        1            B                    7.1
103        3            D                    6.3
104        3            D                    6.5
105        1            B                    7.6
106        2            C                    4.9
107        1            B                    7.3
108        3            D                    6.7
109        1            B                    7.2
110        3            D                    6.5
111        3            D                    6.4
112        3            D                    6.8
113        0            A                    5.7
114        0            A                    5.8
115        3            D                    6.4
116        3            D                    6.5
117        1            B                    7.7
118        1            B                    7.7
119        0            A                    6.0
120        3            D                    6.9
121        0            A                    5.6
122        1            B                    7.7
123        3            D                    6.3
124        3            D                    6.7
125        1            B                    7.2
126        3            D                    6.2
127        0            A                    6.1
128        3            D                    6.4
129        1            B                    7.2
130        1            B                    7.4
131        1            B                    7.9
132        3            D                    6.4
133        3            D                    6.3
134        0            A                    6.1
135        1            B                    7.7
136        3            D                    6.3
137        3            D                    6.4
138        0            A                    6.0
139        3            D                    6.9
140        3            D                    6.7
141        3            D                    6.9
142        0            A                    5.8
143        3            D                    6.8
144        3            D                    6.7
145        3            D                    6.7
146        3            D                    6.3
147        3            D                    6.5
148        3            D                    6.2
149        0            A                    5.9
</pre></div>
</div>
</div>
</div>
</section>
<section id="mengganti-fitur-sepal-length-numeriks-ke-sepal-length-kategorikal">
<h2>Mengganti fitur sepal_length(numeriks) ke sepal_length (kategorikal)<a class="headerlink" href="#mengganti-fitur-sepal-length-numeriks-ke-sepal-length-kategorikal" title="Link to this heading">#</a></h2>
<p>Pada tahap ini, dilakukan proses transformasi fitur sepal_length dari tipe data numerik menjadi kategorikal. Proses ini diawali dengan membaca ulang data iris asli serta data kelas referensi. Data kemudian digabungkan agar fitur sepal_length dapat diproses bersama label kelasnya. Selanjutnya, nilai sepal_length dinormalisasi menggunakan Min-Max Scaler agar seluruh nilai berada dalam rentang 0 hingga 1. Proses normalisasi ini penting untuk meningkatkan performa algoritma K-Means, yang sensitif terhadap skala data.</p>
<p>Setelah dinormalisasi, dilakukan proses klasterisasi menggunakan algoritma K-Means dengan jumlah klaster sebanyak empat. Setiap data kemudian memperoleh label klaster tertentu berdasarkan nilai sepal_length yang dimilikinya. Hasil klasterisasi disimpan dalam kolom baru bernama cluster.Kemudian, nilai klaster tersebut dipetakan ke dalam label kategorikal berupa huruf (‘A’, ‘B’, ‘C’, ‘D’) untuk menggantikan nilai numerik pada fitur sepal_length. Dengan demikian, fitur sepal_length yang semula bertipe numerik kini telah diubah menjadi fitur kategorikal atau diskrit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="n">df_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;clus_dis.xlsx&quot;</span><span class="p">)</span>
<span class="n">df_class</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;class.xlsx&quot;</span><span class="p">)</span>

<span class="c1"># Gabungkan dengan class</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df_features</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="c1"># Clustering ulang fitur sepal_length</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">]]</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>

<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">scaled_features</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>

<span class="c1"># Map hasil cluster ke kategori</span>
<span class="n">cluster_to_category</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span>
    <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span>
    <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span>
    <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;D&#39;</span>
<span class="p">}</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">cluster_to_category</span><span class="p">)</span>

<span class="c1"># Hapus kolom yang tidak perlu</span>
<span class="n">df_result</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">col</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;cluster&#39;</span><span class="p">,</span> <span class="s1">&#39;class&#39;</span><span class="p">,</span> <span class="s1">&#39;predicted_class&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">])</span>

<span class="c1"># Simpan</span>
<span class="n">df_result</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;data_iris_sepal_kategori.xlsx&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Tampilkan sebagian hasil</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      id  petal_length  petal_width sepal_length  sepal_width
0      1           1.4          0.2            B          3.5
1      2           1.4          0.2            B          3.0
2      3           1.3          0.2            B          3.2
3      4           1.5          0.2            B          3.1
4      5           1.4          0.2            B          3.6
5      6           1.7          0.4            A          3.9
6      7           1.4          0.3            B          3.4
7      8           1.5          0.2            B          3.4
8      9           1.4          0.2            B          2.9
9     10           1.5          0.1            B          3.1
10    11           1.5          0.2            A          3.7
11    12           1.6          0.2            B          3.4
12    13           1.4          0.1            B          3.0
13    14           1.1          0.1            B          3.0
14    15           1.2          0.2            A          4.0
15    16           1.5          0.4            A          4.4
16    17           1.3          0.4            A          3.9
17    18           1.4          0.3            B          3.5
18    19           1.7          0.3            A          3.8
19    20           1.5          0.3            B          3.8
20    21           1.7          0.2            A          3.4
21    22           1.5          0.4            B          3.7
22    23           1.0          0.2            B          3.6
23    24           1.7          0.5            B          3.3
24    25           1.9          0.2            B          3.4
25    26           1.6          0.2            B          3.0
26    27           1.6          0.4            B          3.4
27    28           1.5          0.2            B          3.5
28    29           1.4          0.2            B          3.4
29    30           1.6          0.2            B          3.2
30    31           1.6          0.2            B          3.1
31    32           1.5          0.4            A          3.4
32    33           1.5          0.1            B          4.1
33    34           1.4          0.2            A          4.2
34    35           1.5          0.1            B          3.1
35    36           1.2          0.2            B          3.2
36    37           1.3          0.2            A          3.5
37    38           1.5          0.1            B          3.1
38    39           1.3          0.2            B          3.0
39    40           1.5          0.2            B          3.4
40    41           1.3          0.3            B          3.5
41    42           1.3          0.3            B          2.3
42    43           1.3          0.2            B          3.2
43    44           1.6          0.6            B          3.5
44    45           1.9          0.4            B          3.8
45    46           1.4          0.3            B          3.0
46    47           1.6          0.2            B          3.8
47    48           1.4          0.2            B          3.2
48    49           1.5          0.2            B          3.7
49    50           1.4          0.2            B          3.3
50    51           4.7          1.4            C          3.2
51    52           4.5          1.5            C          3.2
52    53           4.9          1.5            C          3.1
53    54           4.0          1.3            A          2.3
54    55           4.6          1.5            C          2.8
55    56           4.5          1.3            A          2.8
56    57           4.7          1.6            C          3.3
57    58           3.3          1.0            B          2.4
58    59           4.6          1.3            C          2.9
59    60           3.9          1.4            B          2.7
60    61           3.5          1.0            B          2.0
61    62           4.2          1.5            A          3.0
62    63           4.0          1.0            A          2.2
63    64           4.7          1.4            A          2.9
64    65           3.6          1.3            A          2.9
65    66           4.4          1.4            C          3.1
66    67           4.5          1.5            A          3.0
67    68           4.1          1.0            A          2.7
68    69           4.5          1.5            C          2.2
69    70           3.9          1.1            A          2.5
70    71           4.8          1.8            A          3.2
71    72           4.0          1.3            A          2.8
72    73           4.9          1.5            C          2.5
73    74           4.7          1.2            A          2.8
74    75           4.3          1.3            C          2.9
75    76           4.4          1.4            C          3.0
76    77           4.8          1.4            C          2.8
77    78           5.0          1.7            C          3.0
78    79           4.5          1.5            A          2.9
79    80           3.5          1.0            A          2.6
80    81           3.8          1.1            A          2.4
81    82           3.7          1.0            A          2.4
82    83           3.9          1.2            A          2.7
83    84           5.1          1.6            A          2.7
84    85           4.5          1.5            A          3.0
85    86           4.5          1.6            A          3.4
86    87           4.7          1.5            C          3.1
87    88           4.4          1.3            C          2.3
88    89           4.1          1.3            A          3.0
89    90           4.0          1.3            A          2.5
90    91           4.4          1.2            A          2.6
91    92           4.6          1.4            A          3.0
92    93           4.0          1.2            A          2.6
93    94           3.3          1.0            B          2.3
94    95           4.2          1.3            A          2.7
95    96           4.2          1.2            A          3.0
96    97           4.2          1.3            A          2.9
97    98           4.3          1.3            C          2.9
98    99           3.0          1.1            B          2.5
99   100           4.1          1.3            A          2.8
100  101           6.0          2.5            C          3.3
101  102           5.1          1.9            A          2.7
102  103           5.9          2.1            D          3.0
103  104           5.6          1.8            C          2.9
104  105           5.8          2.2            C          3.0
105  106           6.6          2.1            D          3.0
106  107           4.5          1.7            B          2.5
107  108           6.3          1.8            D          2.9
108  109           5.8          1.8            C          2.5
109  110           6.1          2.5            D          3.6
110  111           5.1          2.0            C          3.2
111  112           5.3          1.9            C          2.7
112  113           5.5          2.1            C          3.0
113  114           5.0          2.0            A          2.5
114  115           5.1          2.4            A          2.8
115  116           5.3          2.3            C          3.2
116  117           5.5          1.8            C          3.0
117  118           6.7          2.2            D          3.8
118  119           6.9          2.3            D          2.6
119  120           5.0          1.5            A          2.2
120  121           5.7          2.3            C          3.2
121  122           4.9          2.0            A          2.8
122  123           6.7          2.0            D          2.8
123  124           4.9          1.8            C          2.7
124  125           5.7          2.1            C          3.3
125  126           6.0          1.8            D          3.2
126  127           4.8          1.8            C          2.8
127  128           4.9          1.8            A          3.0
128  129           5.6          2.1            C          2.8
129  130           5.8          1.6            D          3.0
130  131           6.1          1.9            D          2.8
131  132           6.4          2.0            D          3.8
132  133           5.6          2.2            C          2.8
133  134           5.1          1.5            C          2.8
134  135           5.6          1.4            A          2.6
135  136           6.1          2.3            D          3.0
136  137           5.6          2.4            C          3.4
137  138           5.5          1.8            C          3.1
138  139           4.8          1.8            A          3.0
139  140           5.4          2.1            C          3.1
140  141           5.6          2.4            C          3.1
141  142           5.1          2.3            C          3.1
142  143           5.1          1.9            A          2.7
143  144           5.9          2.3            C          3.2
144  145           5.7          2.5            C          3.3
145  146           5.2          2.3            C          3.0
146  147           5.0          1.9            C          2.5
147  148           5.2          2.0            C          3.0
148  149           5.4          2.3            C          3.4
149  150           5.1          1.8            A          3.0
</pre></div>
</div>
</div>
</div>
</section>
<section id="melakukan-proses-diskritisasi-dengan-k-means-clustering-pada-fitur-lainya">
<h2>Melakukan proses diskritisasi dengan K-means clustering pada fitur lainya<a class="headerlink" href="#melakukan-proses-diskritisasi-dengan-k-means-clustering-pada-fitur-lainya" title="Link to this heading">#</a></h2>
<p>Setelah sebelumnya dilakukan diskritisasi pada fitur sepal_length, tahap ini melanjutkan proses diskritisasi terhadap fitur numerik lainnya, yaitu sepal_width, petal_length, dan petal_width. Metode yang digunakan adalah K-Means Clustering, yang diterapkan secara terpisah pada masing-masing fitur. Pertama, data iris asli dan versi data yang sudah mengandung sepal_length kategorikal dibaca. Kemudian dibuat sebuah fungsi cluster_kategori_stat() yang bertugas melakukan normalisasi menggunakan Min-Max Scaler, proses clustering dengan KMeans, serta menghasilkan kategori huruf berdasarkan label cluster. Fungsi ini juga menghasilkan statistik nilai minimum, maksimum, dan centroid (rata-rata) untuk setiap cluster dari fitur yang didiskritisasi.</p>
<ul class="simple">
<li><p>Fitur sepal_width dikelompokkan ke dalam 3 kategori (‘A’, ‘B’, ‘C’).</p></li>
<li><p>Fitur petal_length dikelompokkan ke dalam 4 kategori (‘A’, ‘B’, ‘C’, ‘D’).</p></li>
<li><p>Fitur petal_width juga dikelompokkan ke dalam 3 kategori (‘A’, ‘B’, ‘C’).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">KBinsDiscretizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> <span class="c1"># Untuk np.nan jika perlu</span>

<span class="c1"># --- 1. Baca data awal ---</span>
<span class="c1"># Menggunakan nama file yang telah Anda sediakan</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">df_numerik</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;data_iris_sepal_kategori.xlsx&quot;</span><span class="p">)</span>
    <span class="c1"># Untuk df_kategori, kita akan memulainya dari df_numerik dan menambahkan kolom kategori.</span>
    <span class="c1"># Asumsi: sepal_length sudah ada di df_numerik.</span>
    <span class="n">df_kategori</span> <span class="o">=</span> <span class="n">df_numerik</span><span class="p">[[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_length&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">except</span> <span class="ne">FileNotFoundError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading file: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Pastikan file berada di direktori yang sama.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># --- 2. Fungsi bantu diskritisasi + mapping + statistik ---</span>
<span class="k">def</span> <span class="nf">discretize_kbins_stat</span><span class="p">(</span><span class="n">data_col</span><span class="p">,</span> <span class="n">n_bins</span><span class="p">,</span> <span class="n">label_map</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Melakukan diskritisasi menggunakan KBinsDiscretizer dan menghitung statistik.</span>

<span class="sd">    Args:</span>
<span class="sd">        data_col (pd.Series): Kolom data numerik yang akan didiskritisasi.</span>
<span class="sd">        n_bins (int): Jumlah bin/kategori yang diinginkan.</span>
<span class="sd">        label_map (dict): Kamus untuk memetakan label numerik (0, 1, ...) ke label kategori (A, B, ...).</span>
<span class="sd">        strategy (str): Strategi diskritisasi (&#39;uniform&#39;, &#39;quantile&#39;, &#39;kmeans&#39;). Default &#39;kmeans&#39;.</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: (pd.Series kategori, pd.DataFrame statistik)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Inisialisasi KBinsDiscretizer</span>
    <span class="c1"># encode=&#39;ordinal&#39; berarti outputnya adalah integer (0, 1, ...)</span>
    <span class="c1"># strategy=&#39;kmeans&#39; akan mencoba membuat bin berdasarkan klaster KMeans</span>
    <span class="n">discretizer</span> <span class="o">=</span> <span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span> <span class="n">encode</span><span class="o">=</span><span class="s1">&#39;ordinal&#39;</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="n">strategy</span><span class="p">)</span>

    <span class="c1"># Melakukan fitting dan transformasi</span>
    <span class="c1"># Reshape data_col agar sesuai dengan input yang diharapkan oleh scikit-learn (2D array)</span>
    <span class="n">labels_numeric</span> <span class="o">=</span> <span class="n">discretizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data_col</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Membuat seri kategori huruf</span>
    <span class="n">kategori_series</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">labels_numeric</span><span class="p">)</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span>

    <span class="c1"># Menghitung statistik min, max, centroid per cluster/bin</span>
    <span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
        <span class="s1">&#39;nilai_asli&#39;</span><span class="p">:</span> <span class="n">data_col</span><span class="p">,</span>
        <span class="s1">&#39;cluster_id&#39;</span><span class="p">:</span> <span class="n">labels_numeric</span> <span class="c1"># Menggunakan ID cluster/bin numerik</span>
    <span class="p">})</span>

    <span class="c1"># Hitung statistik</span>
    <span class="n">stat</span> <span class="o">=</span> <span class="n">df_temp</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;cluster_id&#39;</span><span class="p">)[</span><span class="s1">&#39;nilai_asli&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">agg</span><span class="p">([</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="s1">&#39;mean&#39;</span><span class="p">])</span>
    <span class="n">stat</span> <span class="o">=</span> <span class="n">stat</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="s1">&#39;centroid&#39;</span><span class="p">})</span> <span class="c1"># Mengganti nama &#39;mean&#39; menjadi &#39;centroid&#39;</span>

    <span class="c1"># Tambahkan kolom kategori ke statistik</span>
    <span class="n">stat</span><span class="p">[</span><span class="s1">&#39;kategori&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">stat</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">label_map</span><span class="p">)</span>
    <span class="n">stat</span> <span class="o">=</span> <span class="n">stat</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;kategori&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">kategori_series</span><span class="p">,</span> <span class="n">stat</span>

<span class="c1"># --- 3. Sepal Width (3 kategori) ---</span>
<span class="n">map_sepal_width</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;C&#39;</span><span class="p">}</span>
<span class="c1"># Menggunakan &#39;kmeans&#39; strategy untuk mendekati perilaku asli</span>
<span class="n">df_kategori</span><span class="p">[</span><span class="s1">&#39;sepal_width&#39;</span><span class="p">],</span> <span class="n">stat_sepal_width</span> <span class="o">=</span> <span class="n">discretize_kbins_stat</span><span class="p">(</span>
    <span class="n">df_numerik</span><span class="p">[</span><span class="s1">&#39;sepal_width&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">map_sepal_width</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span>
<span class="p">)</span>

<span class="c1"># --- 4. Petal Length (4 kategori) ---</span>
<span class="n">map_petal_length</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="mi">3</span><span class="p">:</span> <span class="s1">&#39;D&#39;</span><span class="p">}</span>
<span class="n">df_kategori</span><span class="p">[</span><span class="s1">&#39;petal_length&#39;</span><span class="p">],</span> <span class="n">stat_petal_length</span> <span class="o">=</span> <span class="n">discretize_kbins_stat</span><span class="p">(</span>
    <span class="n">df_numerik</span><span class="p">[</span><span class="s1">&#39;petal_length&#39;</span><span class="p">],</span> <span class="mi">4</span><span class="p">,</span> <span class="n">map_petal_length</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span>
<span class="p">)</span>

<span class="c1"># --- 5. Petal Width (3 kategori) ---</span>
<span class="n">map_petal_width</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span> <span class="s1">&#39;C&#39;</span><span class="p">}</span>
<span class="n">df_kategori</span><span class="p">[</span><span class="s1">&#39;petal_width&#39;</span><span class="p">],</span> <span class="n">stat_petal_width</span> <span class="o">=</span> <span class="n">discretize_kbins_stat</span><span class="p">(</span>
    <span class="n">df_numerik</span><span class="p">[</span><span class="s1">&#39;petal_width&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">map_petal_width</span><span class="p">,</span> <span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;kmeans&#39;</span>
<span class="p">)</span>

<span class="n">df_kategori</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s2">&quot;data_iris_kategori_lengkap.xlsx&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hasil kategori disimpan ke &#39;data_iris_kategori_lengkap.xlsx&#39;&quot;</span><span class="p">)</span>


<span class="c1"># --- 7. Gabungkan semua statistik dan tampilkan ---</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Statistik Sepal Width (3 kategori) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stat_sepal_width</span><span class="p">[[</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="s1">&#39;centroid&#39;</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Statistik Petal Length (4 kategori) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stat_petal_length</span><span class="p">[[</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="s1">&#39;centroid&#39;</span><span class="p">]])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Statistik Petal Width (3 kategori) ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stat_petal_width</span><span class="p">[[</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="s1">&#39;centroid&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hasil kategori disimpan ke &#39;data_iris_kategori_lengkap.xlsx&#39;

=== Statistik Sepal Width (3 kategori) ===
          min  max  centroid
kategori                    
A         2.0  2.8  2.585106
B         2.9  3.4  3.118987
C         3.5  4.4  3.758333

=== Statistik Petal Length (4 kategori) ===
          min  max  centroid
kategori                    
A         1.0  1.9  1.464000
B         3.0  4.3  3.884000
C         4.4  5.3  4.808889
D         5.4  6.9  5.903333

=== Statistik Petal Width (3 kategori) ===
          min  max  centroid
kategori                    
A         0.1  0.6  0.244000
B         1.0  1.7  1.337037
C         1.8  2.5  2.073913
</pre></div>
</div>
</div>
</div>
</section>
<section id="menampilkan-semua-data-hasil-diskritisasi-setiap-fitur">
<h2>Menampilkan semua data hasil diskritisasi setiap fitur<a class="headerlink" href="#menampilkan-semua-data-hasil-diskritisasi-setiap-fitur" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Baca file Excel yang sudah berisi kategori</span>
<span class="n">df_kategori</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;data_iris_kategori_lengkap.xlsx&quot;</span><span class="p">)</span>

<span class="c1"># Tampilkan semua baris</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_kategori</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>      id sepal_length sepal_width petal_length petal_width
0      1            B           C            A           A
1      2            B           B            A           A
2      3            B           B            A           A
3      4            B           B            A           A
4      5            B           C            A           A
5      6            A           C            A           A
6      7            B           B            A           A
7      8            B           B            A           A
8      9            B           B            A           A
9     10            B           B            A           A
10    11            A           C            A           A
11    12            B           B            A           A
12    13            B           B            A           A
13    14            B           B            A           A
14    15            A           C            A           A
15    16            A           C            A           A
16    17            A           C            A           A
17    18            B           C            A           A
18    19            A           C            A           A
19    20            B           C            A           A
20    21            A           B            A           A
21    22            B           C            A           A
22    23            B           C            A           A
23    24            B           B            A           A
24    25            B           B            A           A
25    26            B           B            A           A
26    27            B           B            A           A
27    28            B           C            A           A
28    29            B           B            A           A
29    30            B           B            A           A
30    31            B           B            A           A
31    32            A           B            A           A
32    33            B           C            A           A
33    34            A           C            A           A
34    35            B           B            A           A
35    36            B           B            A           A
36    37            A           C            A           A
37    38            B           B            A           A
38    39            B           B            A           A
39    40            B           B            A           A
40    41            B           C            A           A
41    42            B           A            A           A
42    43            B           B            A           A
43    44            B           C            A           A
44    45            B           C            A           A
45    46            B           B            A           A
46    47            B           C            A           A
47    48            B           B            A           A
48    49            B           C            A           A
49    50            B           B            A           A
50    51            C           B            C           B
51    52            C           B            C           B
52    53            C           B            C           B
53    54            A           A            B           B
54    55            C           A            C           B
55    56            A           A            C           B
56    57            C           B            C           B
57    58            B           A            B           B
58    59            C           B            C           B
59    60            B           A            B           B
60    61            B           A            B           B
61    62            A           B            B           B
62    63            A           A            B           B
63    64            A           B            C           B
64    65            A           B            B           B
65    66            C           B            C           B
66    67            A           B            C           B
67    68            A           A            B           B
68    69            C           A            C           B
69    70            A           A            B           B
70    71            A           B            C           C
71    72            A           A            B           B
72    73            C           A            C           B
73    74            A           A            C           B
74    75            C           B            B           B
75    76            C           B            C           B
76    77            C           A            C           B
77    78            C           B            C           B
78    79            A           B            C           B
79    80            A           A            B           B
80    81            A           A            B           B
81    82            A           A            B           B
82    83            A           A            B           B
83    84            A           A            C           B
84    85            A           B            C           B
85    86            A           B            C           B
86    87            C           B            C           B
87    88            C           A            C           B
88    89            A           B            B           B
89    90            A           A            B           B
90    91            A           A            C           B
91    92            A           B            C           B
92    93            A           A            B           B
93    94            B           A            B           B
94    95            A           A            B           B
95    96            A           B            B           B
96    97            A           B            B           B
97    98            C           B            B           B
98    99            B           A            B           B
99   100            A           A            B           B
100  101            C           B            D           C
101  102            A           A            C           C
102  103            D           B            D           C
103  104            C           B            D           C
104  105            C           B            D           C
105  106            D           B            D           C
106  107            B           A            C           B
107  108            D           B            D           C
108  109            C           A            D           C
109  110            D           C            D           C
110  111            C           B            C           C
111  112            C           A            C           C
112  113            C           B            D           C
113  114            A           A            C           C
114  115            A           A            C           C
115  116            C           B            C           C
116  117            C           B            D           C
117  118            D           C            D           C
118  119            D           A            D           C
119  120            A           A            C           B
120  121            C           B            D           C
121  122            A           A            C           C
122  123            D           A            D           C
123  124            C           A            C           C
124  125            C           B            D           C
125  126            D           B            D           C
126  127            C           A            C           C
127  128            A           B            C           C
128  129            C           A            D           C
129  130            D           B            D           B
130  131            D           A            D           C
131  132            D           C            D           C
132  133            C           A            D           C
133  134            C           A            C           B
134  135            A           A            D           B
135  136            D           B            D           C
136  137            C           B            D           C
137  138            C           B            D           C
138  139            A           B            C           C
139  140            C           B            D           C
140  141            C           B            D           C
141  142            C           B            C           C
142  143            A           A            C           C
143  144            C           B            D           C
144  145            C           B            D           C
145  146            C           B            C           C
146  147            C           A            C           C
147  148            C           B            C           C
148  149            C           B            D           C
149  150            A           B            C           C
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-naive-bayes-data-diskrit">
<h2>Klasifikasi Naive Bayes Data Diskrit<a class="headerlink" href="#klasifikasi-naive-bayes-data-diskrit" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">CategoricalNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Load both files</span>
<span class="n">data_iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;data_iris_kategori_lengkap.xlsx&quot;</span><span class="p">)</span>
<span class="n">class_asli</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;class.xlsx&quot;</span><span class="p">)</span>

<span class="c1"># Gabungkan data kategorikal dengan kelas asli berdasarkan &#39;id&#39;</span>
<span class="n">data_gabungan</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">data_iris</span><span class="p">,</span> <span class="n">class_asli</span><span class="p">[[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;class&#39;</span><span class="p">]],</span> <span class="n">on</span><span class="o">=</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>

<span class="c1"># Encode fitur kategorikal (A, B, dst.) ke numerik</span>
<span class="n">fitur_kategori</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">kolom</span> <span class="ow">in</span> <span class="n">fitur_kategori</span><span class="p">:</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
    <span class="n">data_gabungan</span><span class="p">[</span><span class="n">kolom</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data_gabungan</span><span class="p">[</span><span class="n">kolom</span><span class="p">])</span>

<span class="c1"># Encode label kelas</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data_gabungan</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data_gabungan</span><span class="p">[</span><span class="n">fitur_kategori</span><span class="p">]</span>

<span class="c1"># Model Naive Bayes</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">CategoricalNB</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Buat DataFrame hasil prediksi vs kelas asli</span>
<span class="n">hasil_prediksi</span> <span class="o">=</span> <span class="n">data_gabungan</span><span class="p">[[</span><span class="s1">&#39;id&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">hasil_prediksi</span><span class="p">[</span><span class="s1">&#39;kelas_asli&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">hasil_prediksi</span><span class="p">[</span><span class="s1">&#39;kelas_prediksi&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

<span class="c1"># Simpan ke Excel</span>
<span class="n">output_path</span> <span class="o">=</span> <span class="s2">&quot;naive_bayes.xlsx&quot;</span>
<span class="n">hasil_prediksi</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Evaluasi hasil prediksi</span>
<span class="n">akurasi</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">laporan_klasifikasi</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">label_encoder</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>

<span class="c1"># Tampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Hasil Prediksi Kelas ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">hasil_prediksi</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Akurasi ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi: </span><span class="si">{</span><span class="n">akurasi</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== Laporan Klasifikasi ===&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">laporan_klasifikasi</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>=== Hasil Prediksi Kelas ===
      id       kelas_asli   kelas_prediksi
0      1      Iris-setosa      Iris-setosa
1      2      Iris-setosa      Iris-setosa
2      3      Iris-setosa      Iris-setosa
3      4      Iris-setosa      Iris-setosa
4      5      Iris-setosa      Iris-setosa
5      6      Iris-setosa      Iris-setosa
6      7      Iris-setosa      Iris-setosa
7      8      Iris-setosa      Iris-setosa
8      9      Iris-setosa      Iris-setosa
9     10      Iris-setosa      Iris-setosa
10    11      Iris-setosa      Iris-setosa
11    12      Iris-setosa      Iris-setosa
12    13      Iris-setosa      Iris-setosa
13    14      Iris-setosa      Iris-setosa
14    15      Iris-setosa      Iris-setosa
15    16      Iris-setosa      Iris-setosa
16    17      Iris-setosa      Iris-setosa
17    18      Iris-setosa      Iris-setosa
18    19      Iris-setosa      Iris-setosa
19    20      Iris-setosa      Iris-setosa
20    21      Iris-setosa      Iris-setosa
21    22      Iris-setosa      Iris-setosa
22    23      Iris-setosa      Iris-setosa
23    24      Iris-setosa      Iris-setosa
24    25      Iris-setosa      Iris-setosa
25    26      Iris-setosa      Iris-setosa
26    27      Iris-setosa      Iris-setosa
27    28      Iris-setosa      Iris-setosa
28    29      Iris-setosa      Iris-setosa
29    30      Iris-setosa      Iris-setosa
30    31      Iris-setosa      Iris-setosa
31    32      Iris-setosa      Iris-setosa
32    33      Iris-setosa      Iris-setosa
33    34      Iris-setosa      Iris-setosa
34    35      Iris-setosa      Iris-setosa
35    36      Iris-setosa      Iris-setosa
36    37      Iris-setosa      Iris-setosa
37    38      Iris-setosa      Iris-setosa
38    39      Iris-setosa      Iris-setosa
39    40      Iris-setosa      Iris-setosa
40    41      Iris-setosa      Iris-setosa
41    42      Iris-setosa      Iris-setosa
42    43      Iris-setosa      Iris-setosa
43    44      Iris-setosa      Iris-setosa
44    45      Iris-setosa      Iris-setosa
45    46      Iris-setosa      Iris-setosa
46    47      Iris-setosa      Iris-setosa
47    48      Iris-setosa      Iris-setosa
48    49      Iris-setosa      Iris-setosa
49    50      Iris-setosa      Iris-setosa
50    51  Iris-versicolor  Iris-versicolor
51    52  Iris-versicolor  Iris-versicolor
52    53  Iris-versicolor  Iris-versicolor
53    54  Iris-versicolor  Iris-versicolor
54    55  Iris-versicolor  Iris-versicolor
55    56  Iris-versicolor  Iris-versicolor
56    57  Iris-versicolor  Iris-versicolor
57    58  Iris-versicolor  Iris-versicolor
58    59  Iris-versicolor  Iris-versicolor
59    60  Iris-versicolor  Iris-versicolor
60    61  Iris-versicolor  Iris-versicolor
61    62  Iris-versicolor  Iris-versicolor
62    63  Iris-versicolor  Iris-versicolor
63    64  Iris-versicolor  Iris-versicolor
64    65  Iris-versicolor  Iris-versicolor
65    66  Iris-versicolor  Iris-versicolor
66    67  Iris-versicolor  Iris-versicolor
67    68  Iris-versicolor  Iris-versicolor
68    69  Iris-versicolor  Iris-versicolor
69    70  Iris-versicolor  Iris-versicolor
70    71  Iris-versicolor   Iris-virginica
71    72  Iris-versicolor  Iris-versicolor
72    73  Iris-versicolor  Iris-versicolor
73    74  Iris-versicolor  Iris-versicolor
74    75  Iris-versicolor  Iris-versicolor
75    76  Iris-versicolor  Iris-versicolor
76    77  Iris-versicolor  Iris-versicolor
77    78  Iris-versicolor  Iris-versicolor
78    79  Iris-versicolor  Iris-versicolor
79    80  Iris-versicolor  Iris-versicolor
80    81  Iris-versicolor  Iris-versicolor
81    82  Iris-versicolor  Iris-versicolor
82    83  Iris-versicolor  Iris-versicolor
83    84  Iris-versicolor  Iris-versicolor
84    85  Iris-versicolor  Iris-versicolor
85    86  Iris-versicolor  Iris-versicolor
86    87  Iris-versicolor  Iris-versicolor
87    88  Iris-versicolor  Iris-versicolor
88    89  Iris-versicolor  Iris-versicolor
89    90  Iris-versicolor  Iris-versicolor
90    91  Iris-versicolor  Iris-versicolor
91    92  Iris-versicolor  Iris-versicolor
92    93  Iris-versicolor  Iris-versicolor
93    94  Iris-versicolor  Iris-versicolor
94    95  Iris-versicolor  Iris-versicolor
95    96  Iris-versicolor  Iris-versicolor
96    97  Iris-versicolor  Iris-versicolor
97    98  Iris-versicolor  Iris-versicolor
98    99  Iris-versicolor  Iris-versicolor
99   100  Iris-versicolor  Iris-versicolor
100  101   Iris-virginica   Iris-virginica
101  102   Iris-virginica   Iris-virginica
102  103   Iris-virginica   Iris-virginica
103  104   Iris-virginica   Iris-virginica
104  105   Iris-virginica   Iris-virginica
105  106   Iris-virginica   Iris-virginica
106  107   Iris-virginica  Iris-versicolor
107  108   Iris-virginica   Iris-virginica
108  109   Iris-virginica   Iris-virginica
109  110   Iris-virginica   Iris-virginica
110  111   Iris-virginica   Iris-virginica
111  112   Iris-virginica   Iris-virginica
112  113   Iris-virginica   Iris-virginica
113  114   Iris-virginica   Iris-virginica
114  115   Iris-virginica   Iris-virginica
115  116   Iris-virginica   Iris-virginica
116  117   Iris-virginica   Iris-virginica
117  118   Iris-virginica   Iris-virginica
118  119   Iris-virginica   Iris-virginica
119  120   Iris-virginica  Iris-versicolor
120  121   Iris-virginica   Iris-virginica
121  122   Iris-virginica   Iris-virginica
122  123   Iris-virginica   Iris-virginica
123  124   Iris-virginica   Iris-virginica
124  125   Iris-virginica   Iris-virginica
125  126   Iris-virginica   Iris-virginica
126  127   Iris-virginica   Iris-virginica
127  128   Iris-virginica   Iris-virginica
128  129   Iris-virginica   Iris-virginica
129  130   Iris-virginica   Iris-virginica
130  131   Iris-virginica   Iris-virginica
131  132   Iris-virginica   Iris-virginica
132  133   Iris-virginica   Iris-virginica
133  134   Iris-virginica  Iris-versicolor
134  135   Iris-virginica  Iris-versicolor
135  136   Iris-virginica   Iris-virginica
136  137   Iris-virginica   Iris-virginica
137  138   Iris-virginica   Iris-virginica
138  139   Iris-virginica   Iris-virginica
139  140   Iris-virginica   Iris-virginica
140  141   Iris-virginica   Iris-virginica
141  142   Iris-virginica   Iris-virginica
142  143   Iris-virginica   Iris-virginica
143  144   Iris-virginica   Iris-virginica
144  145   Iris-virginica   Iris-virginica
145  146   Iris-virginica   Iris-virginica
146  147   Iris-virginica   Iris-virginica
147  148   Iris-virginica   Iris-virginica
148  149   Iris-virginica   Iris-virginica
149  150   Iris-virginica   Iris-virginica

=== Akurasi ===
Akurasi: 0.97

=== Laporan Klasifikasi ===
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        50
Iris-versicolor       0.92      0.98      0.95        50
 Iris-virginica       0.98      0.92      0.95        50

       accuracy                           0.97       150
      macro avg       0.97      0.97      0.97       150
   weighted avg       0.97      0.97      0.97       150
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-naive-bayes-data-tanpa-diskritisasi">
<h2>Klasifikasi Naive Bayes Data Tanpa Diskritisasi<a class="headerlink" href="#klasifikasi-naive-bayes-data-tanpa-diskritisasi" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># Memuat dataset</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">df_iris</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data_iris.xlsx&#39;</span><span class="p">)</span>
    <span class="n">df_class</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;class.xlsx&#39;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">FileNotFoundError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading file: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Pastikan file berada di direktori yang sama.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># Menyiapkan data</span>
<span class="c1"># Fitur (X) diambil dari df_iris, mengecualikan kolom &#39;id&#39;</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_iris</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Label sebenarnya (y_true) diambil dari kolom &#39;class&#39; di df_class</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">df_class</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="c1"># Memastikan jumlah baris di X dan y_true cocok</span>
<span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error: Jumlah baris pada fitur dan variabel target sebenarnya tidak cocok.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># Menginisialisasi model Gaussian Naive Bayes</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Melatih model menggunakan fitur dari df_iris dan label sebenarnya dari df_class</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y_true</span><span class="p">)</span>

<span class="c1"># Membuat prediksi pada fitur yang sama</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Membandingkan prediksi dengan kelas aktual (y_true)</span>
<span class="n">comparison_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;True Class&#39;</span><span class="p">:</span> <span class="n">y_true</span><span class="p">,</span> <span class="s1">&#39;Predicted Class&#39;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Perbandingan Kelas Aktual dan Kelas Prediksi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">comparison_df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="c1"># Mengevaluasi model</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Akurasi: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Matriks Konfusi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Laporan Klasifikasi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="n">comparison_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;naive_bayes_classification_results.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Perbandingan Kelas Aktual dan Kelas Prediksi:
    True Class Predicted Class
0  Iris-setosa     Iris-setosa
1  Iris-setosa     Iris-setosa
2  Iris-setosa     Iris-setosa
3  Iris-setosa     Iris-setosa
4  Iris-setosa     Iris-setosa

Akurasi: 0.9600

Matriks Konfusi:
[[50  0  0]
 [ 0 47  3]
 [ 0  3 47]]

Laporan Klasifikasi:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        50
Iris-versicolor       0.94      0.94      0.94        50
 Iris-virginica       0.94      0.94      0.94        50

       accuracy                           0.96       150
      macro avg       0.96      0.96      0.96       150
   weighted avg       0.96      0.96      0.96       150
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-decision-tree-data-diskrit">
<h2>Klasifikasi Decision Tree Data Diskrit<a class="headerlink" href="#klasifikasi-decision-tree-data-diskrit" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="c1"># Meskipun tidak digunakan untuk split di sini, ini adalah praktik baik</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="c1"># --- 1. Memuat data yang sudah didiskritisasi ---</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">df_discretized</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data_iris_kategori_lengkap.xlsx&#39;</span><span class="p">)</span>
    <span class="n">df_true_class</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;class.xlsx&#39;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">FileNotFoundError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading file: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Pastikan file berada di direktori yang sama.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># --- 2. Menyiapkan data ---</span>
<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">]</span>
<span class="n">X_categorical</span> <span class="o">=</span> <span class="n">df_discretized</span><span class="p">[</span><span class="n">categorical_features</span><span class="p">]</span>

<span class="c1"># Variabel target (y) dari file kelas aktual</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_true_class</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">sparse_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X_encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_categorical</span><span class="p">)</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">(</span><span class="n">categorical_features</span><span class="p">)</span>
<span class="n">X_df_encoded</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_encoded</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>

<span class="k">if</span> <span class="n">X_df_encoded</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error: Jumlah baris pada fitur yang di-encode dan variabel target tidak cocok.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># --- 3. Melatih pengklasifikasi Decision Tree ---</span>
<span class="c1"># random_state digunakan untuk reproduksibilitas hasil</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Melatih model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_df_encoded</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># --- 4. Membuat prediksi ---</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_df_encoded</span><span class="p">)</span>

<span class="c1"># --- 5. Mengevaluasi model ---</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Akurasi Model Decision Tree (Data Diskritisasi): </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Matriks Konfusi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Laporan Klasifikasi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="c1"># Secara opsional, simpan perbandingan kelas aktual dan prediksi ke file CSV</span>
<span class="n">comparison_df_dt</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;True Class&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;Predicted Class&#39;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">})</span>
<span class="n">comparison_df_dt</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;decision_tree_discretized_classification_results.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi Model Decision Tree (Data Diskritisasi): 0.9800

Matriks Konfusi:
[[50  0  0]
 [ 0 49  1]
 [ 0  2 48]]

Laporan Klasifikasi:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        50
Iris-versicolor       0.96      0.98      0.97        50
 Iris-virginica       0.98      0.96      0.97        50

       accuracy                           0.98       150
      macro avg       0.98      0.98      0.98       150
   weighted avg       0.98      0.98      0.98       150
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;decision_tree_discretized_classification_results.xlsx&#39;</span><span class="p">)</span>
<span class="c1"># Tampilkan semua baris</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          True Class  Predicted Class
0        Iris-setosa      Iris-setosa
1        Iris-setosa      Iris-setosa
2        Iris-setosa      Iris-setosa
3        Iris-setosa      Iris-setosa
4        Iris-setosa      Iris-setosa
5        Iris-setosa      Iris-setosa
6        Iris-setosa      Iris-setosa
7        Iris-setosa      Iris-setosa
8        Iris-setosa      Iris-setosa
9        Iris-setosa      Iris-setosa
10       Iris-setosa      Iris-setosa
11       Iris-setosa      Iris-setosa
12       Iris-setosa      Iris-setosa
13       Iris-setosa      Iris-setosa
14       Iris-setosa      Iris-setosa
15       Iris-setosa      Iris-setosa
16       Iris-setosa      Iris-setosa
17       Iris-setosa      Iris-setosa
18       Iris-setosa      Iris-setosa
19       Iris-setosa      Iris-setosa
20       Iris-setosa      Iris-setosa
21       Iris-setosa      Iris-setosa
22       Iris-setosa      Iris-setosa
23       Iris-setosa      Iris-setosa
24       Iris-setosa      Iris-setosa
25       Iris-setosa      Iris-setosa
26       Iris-setosa      Iris-setosa
27       Iris-setosa      Iris-setosa
28       Iris-setosa      Iris-setosa
29       Iris-setosa      Iris-setosa
30       Iris-setosa      Iris-setosa
31       Iris-setosa      Iris-setosa
32       Iris-setosa      Iris-setosa
33       Iris-setosa      Iris-setosa
34       Iris-setosa      Iris-setosa
35       Iris-setosa      Iris-setosa
36       Iris-setosa      Iris-setosa
37       Iris-setosa      Iris-setosa
38       Iris-setosa      Iris-setosa
39       Iris-setosa      Iris-setosa
40       Iris-setosa      Iris-setosa
41       Iris-setosa      Iris-setosa
42       Iris-setosa      Iris-setosa
43       Iris-setosa      Iris-setosa
44       Iris-setosa      Iris-setosa
45       Iris-setosa      Iris-setosa
46       Iris-setosa      Iris-setosa
47       Iris-setosa      Iris-setosa
48       Iris-setosa      Iris-setosa
49       Iris-setosa      Iris-setosa
50   Iris-versicolor  Iris-versicolor
51   Iris-versicolor  Iris-versicolor
52   Iris-versicolor  Iris-versicolor
53   Iris-versicolor  Iris-versicolor
54   Iris-versicolor  Iris-versicolor
55   Iris-versicolor  Iris-versicolor
56   Iris-versicolor  Iris-versicolor
57   Iris-versicolor  Iris-versicolor
58   Iris-versicolor  Iris-versicolor
59   Iris-versicolor  Iris-versicolor
60   Iris-versicolor  Iris-versicolor
61   Iris-versicolor  Iris-versicolor
62   Iris-versicolor  Iris-versicolor
63   Iris-versicolor  Iris-versicolor
64   Iris-versicolor  Iris-versicolor
65   Iris-versicolor  Iris-versicolor
66   Iris-versicolor  Iris-versicolor
67   Iris-versicolor  Iris-versicolor
68   Iris-versicolor  Iris-versicolor
69   Iris-versicolor  Iris-versicolor
70   Iris-versicolor   Iris-virginica
71   Iris-versicolor  Iris-versicolor
72   Iris-versicolor  Iris-versicolor
73   Iris-versicolor  Iris-versicolor
74   Iris-versicolor  Iris-versicolor
75   Iris-versicolor  Iris-versicolor
76   Iris-versicolor  Iris-versicolor
77   Iris-versicolor  Iris-versicolor
78   Iris-versicolor  Iris-versicolor
79   Iris-versicolor  Iris-versicolor
80   Iris-versicolor  Iris-versicolor
81   Iris-versicolor  Iris-versicolor
82   Iris-versicolor  Iris-versicolor
83   Iris-versicolor  Iris-versicolor
84   Iris-versicolor  Iris-versicolor
85   Iris-versicolor  Iris-versicolor
86   Iris-versicolor  Iris-versicolor
87   Iris-versicolor  Iris-versicolor
88   Iris-versicolor  Iris-versicolor
89   Iris-versicolor  Iris-versicolor
90   Iris-versicolor  Iris-versicolor
91   Iris-versicolor  Iris-versicolor
92   Iris-versicolor  Iris-versicolor
93   Iris-versicolor  Iris-versicolor
94   Iris-versicolor  Iris-versicolor
95   Iris-versicolor  Iris-versicolor
96   Iris-versicolor  Iris-versicolor
97   Iris-versicolor  Iris-versicolor
98   Iris-versicolor  Iris-versicolor
99   Iris-versicolor  Iris-versicolor
100   Iris-virginica   Iris-virginica
101   Iris-virginica   Iris-virginica
102   Iris-virginica   Iris-virginica
103   Iris-virginica   Iris-virginica
104   Iris-virginica   Iris-virginica
105   Iris-virginica   Iris-virginica
106   Iris-virginica   Iris-virginica
107   Iris-virginica   Iris-virginica
108   Iris-virginica   Iris-virginica
109   Iris-virginica   Iris-virginica
110   Iris-virginica   Iris-virginica
111   Iris-virginica   Iris-virginica
112   Iris-virginica   Iris-virginica
113   Iris-virginica   Iris-virginica
114   Iris-virginica   Iris-virginica
115   Iris-virginica   Iris-virginica
116   Iris-virginica   Iris-virginica
117   Iris-virginica   Iris-virginica
118   Iris-virginica   Iris-virginica
119   Iris-virginica  Iris-versicolor
120   Iris-virginica   Iris-virginica
121   Iris-virginica   Iris-virginica
122   Iris-virginica   Iris-virginica
123   Iris-virginica   Iris-virginica
124   Iris-virginica   Iris-virginica
125   Iris-virginica   Iris-virginica
126   Iris-virginica   Iris-virginica
127   Iris-virginica   Iris-virginica
128   Iris-virginica   Iris-virginica
129   Iris-virginica   Iris-virginica
130   Iris-virginica   Iris-virginica
131   Iris-virginica   Iris-virginica
132   Iris-virginica   Iris-virginica
133   Iris-virginica  Iris-versicolor
134   Iris-virginica   Iris-virginica
135   Iris-virginica   Iris-virginica
136   Iris-virginica   Iris-virginica
137   Iris-virginica   Iris-virginica
138   Iris-virginica   Iris-virginica
139   Iris-virginica   Iris-virginica
140   Iris-virginica   Iris-virginica
141   Iris-virginica   Iris-virginica
142   Iris-virginica   Iris-virginica
143   Iris-virginica   Iris-virginica
144   Iris-virginica   Iris-virginica
145   Iris-virginica   Iris-virginica
146   Iris-virginica   Iris-virginica
147   Iris-virginica   Iris-virginica
148   Iris-virginica   Iris-virginica
149   Iris-virginica   Iris-virginica
</pre></div>
</div>
</div>
</div>
</section>
<section id="klasifikasi-decision-tree-data-tanpa-diskritisasi">
<h2>Klasifikasi Decision Tree Data Tanpa Diskritisasi<a class="headerlink" href="#klasifikasi-decision-tree-data-tanpa-diskritisasi" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span> <span class="c1"># Termasuk untuk praktik baik</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># --- 1. Memuat data Iris asli ---</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">df_iris_original</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;data_iris.xlsx&#39;</span><span class="p">)</span>
    <span class="n">df_true_class</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;class.xlsx&#39;</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">FileNotFoundError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error loading file: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">. Pastikan file berada di direktori yang sama.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># --- 2. Menyiapkan data ---</span>
<span class="c1"># Fitur (X) dari data Iris asli, mengecualikan kolom &#39;id&#39;</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;petal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;petal_width&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_length&#39;</span><span class="p">,</span> <span class="s1">&#39;sepal_width&#39;</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_iris_original</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>

<span class="c1"># Variabel target (y) dari file kelas aktual</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_true_class</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="c1"># Memastikan jumlah sampel di X dan y cocok</span>
<span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error: Jumlah baris pada fitur dan variabel target tidak cocok.&quot;</span><span class="p">)</span>
    <span class="n">exit</span><span class="p">()</span>

<span class="c1"># Untuk tujuan demonstrasi ini, kita akan melatih dan mengevaluasi pada seluruh dataset.</span>
<span class="c1"># Dalam skenario dunia nyata, sangat disarankan untuk menggunakan train_test_split</span>
<span class="c1"># untuk membagi data menjadi set pelatihan dan pengujian guna mendapatkan evaluasi model yang lebih realistis.</span>
<span class="c1"># Contoh penggunaan train_test_split:</span>
<span class="c1"># X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)</span>

<span class="c1"># --- 3. Melatih pengklasifikasi Decision Tree ---</span>
<span class="c1"># random_state digunakan untuk reproduksibilitas hasil</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Melatih model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># --- 4. Membuat prediksi ---</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># --- 5. Mengevaluasi model ---</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">class_report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Akurasi Model Decision Tree (Data Iris Asli): </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Matriks Konfusi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Laporan Klasifikasi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">class_report</span><span class="p">)</span>

<span class="n">comparison_df_dt_original</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;True Class&#39;</span><span class="p">:</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;Predicted Class&#39;</span><span class="p">:</span> <span class="n">y_pred</span><span class="p">})</span>
<span class="n">comparison_df_dt_original</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;decision_tree_original_iris_classification_results.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi Model Decision Tree (Data Iris Asli): 1.0000

Matriks Konfusi:
[[50  0  0]
 [ 0 50  0]
 [ 0  0 50]]

Laporan Klasifikasi:
                 precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        50
Iris-versicolor       1.00      1.00      1.00        50
 Iris-virginica       1.00      1.00      1.00        50

       accuracy                           1.00       150
      macro avg       1.00      1.00      1.00       150
   weighted avg       1.00      1.00      1.00       150
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">df</span><span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;decision_tree_original_iris_classification_results.xlsx&#39;</span><span class="p">)</span>

<span class="c1"># Tampilkan semua baris</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>          True Class  Predicted Class
0        Iris-setosa      Iris-setosa
1        Iris-setosa      Iris-setosa
2        Iris-setosa      Iris-setosa
3        Iris-setosa      Iris-setosa
4        Iris-setosa      Iris-setosa
5        Iris-setosa      Iris-setosa
6        Iris-setosa      Iris-setosa
7        Iris-setosa      Iris-setosa
8        Iris-setosa      Iris-setosa
9        Iris-setosa      Iris-setosa
10       Iris-setosa      Iris-setosa
11       Iris-setosa      Iris-setosa
12       Iris-setosa      Iris-setosa
13       Iris-setosa      Iris-setosa
14       Iris-setosa      Iris-setosa
15       Iris-setosa      Iris-setosa
16       Iris-setosa      Iris-setosa
17       Iris-setosa      Iris-setosa
18       Iris-setosa      Iris-setosa
19       Iris-setosa      Iris-setosa
20       Iris-setosa      Iris-setosa
21       Iris-setosa      Iris-setosa
22       Iris-setosa      Iris-setosa
23       Iris-setosa      Iris-setosa
24       Iris-setosa      Iris-setosa
25       Iris-setosa      Iris-setosa
26       Iris-setosa      Iris-setosa
27       Iris-setosa      Iris-setosa
28       Iris-setosa      Iris-setosa
29       Iris-setosa      Iris-setosa
30       Iris-setosa      Iris-setosa
31       Iris-setosa      Iris-setosa
32       Iris-setosa      Iris-setosa
33       Iris-setosa      Iris-setosa
34       Iris-setosa      Iris-setosa
35       Iris-setosa      Iris-setosa
36       Iris-setosa      Iris-setosa
37       Iris-setosa      Iris-setosa
38       Iris-setosa      Iris-setosa
39       Iris-setosa      Iris-setosa
40       Iris-setosa      Iris-setosa
41       Iris-setosa      Iris-setosa
42       Iris-setosa      Iris-setosa
43       Iris-setosa      Iris-setosa
44       Iris-setosa      Iris-setosa
45       Iris-setosa      Iris-setosa
46       Iris-setosa      Iris-setosa
47       Iris-setosa      Iris-setosa
48       Iris-setosa      Iris-setosa
49       Iris-setosa      Iris-setosa
50   Iris-versicolor  Iris-versicolor
51   Iris-versicolor  Iris-versicolor
52   Iris-versicolor  Iris-versicolor
53   Iris-versicolor  Iris-versicolor
54   Iris-versicolor  Iris-versicolor
55   Iris-versicolor  Iris-versicolor
56   Iris-versicolor  Iris-versicolor
57   Iris-versicolor  Iris-versicolor
58   Iris-versicolor  Iris-versicolor
59   Iris-versicolor  Iris-versicolor
60   Iris-versicolor  Iris-versicolor
61   Iris-versicolor  Iris-versicolor
62   Iris-versicolor  Iris-versicolor
63   Iris-versicolor  Iris-versicolor
64   Iris-versicolor  Iris-versicolor
65   Iris-versicolor  Iris-versicolor
66   Iris-versicolor  Iris-versicolor
67   Iris-versicolor  Iris-versicolor
68   Iris-versicolor  Iris-versicolor
69   Iris-versicolor  Iris-versicolor
70   Iris-versicolor  Iris-versicolor
71   Iris-versicolor  Iris-versicolor
72   Iris-versicolor  Iris-versicolor
73   Iris-versicolor  Iris-versicolor
74   Iris-versicolor  Iris-versicolor
75   Iris-versicolor  Iris-versicolor
76   Iris-versicolor  Iris-versicolor
77   Iris-versicolor  Iris-versicolor
78   Iris-versicolor  Iris-versicolor
79   Iris-versicolor  Iris-versicolor
80   Iris-versicolor  Iris-versicolor
81   Iris-versicolor  Iris-versicolor
82   Iris-versicolor  Iris-versicolor
83   Iris-versicolor  Iris-versicolor
84   Iris-versicolor  Iris-versicolor
85   Iris-versicolor  Iris-versicolor
86   Iris-versicolor  Iris-versicolor
87   Iris-versicolor  Iris-versicolor
88   Iris-versicolor  Iris-versicolor
89   Iris-versicolor  Iris-versicolor
90   Iris-versicolor  Iris-versicolor
91   Iris-versicolor  Iris-versicolor
92   Iris-versicolor  Iris-versicolor
93   Iris-versicolor  Iris-versicolor
94   Iris-versicolor  Iris-versicolor
95   Iris-versicolor  Iris-versicolor
96   Iris-versicolor  Iris-versicolor
97   Iris-versicolor  Iris-versicolor
98   Iris-versicolor  Iris-versicolor
99   Iris-versicolor  Iris-versicolor
100   Iris-virginica   Iris-virginica
101   Iris-virginica   Iris-virginica
102   Iris-virginica   Iris-virginica
103   Iris-virginica   Iris-virginica
104   Iris-virginica   Iris-virginica
105   Iris-virginica   Iris-virginica
106   Iris-virginica   Iris-virginica
107   Iris-virginica   Iris-virginica
108   Iris-virginica   Iris-virginica
109   Iris-virginica   Iris-virginica
110   Iris-virginica   Iris-virginica
111   Iris-virginica   Iris-virginica
112   Iris-virginica   Iris-virginica
113   Iris-virginica   Iris-virginica
114   Iris-virginica   Iris-virginica
115   Iris-virginica   Iris-virginica
116   Iris-virginica   Iris-virginica
117   Iris-virginica   Iris-virginica
118   Iris-virginica   Iris-virginica
119   Iris-virginica   Iris-virginica
120   Iris-virginica   Iris-virginica
121   Iris-virginica   Iris-virginica
122   Iris-virginica   Iris-virginica
123   Iris-virginica   Iris-virginica
124   Iris-virginica   Iris-virginica
125   Iris-virginica   Iris-virginica
126   Iris-virginica   Iris-virginica
127   Iris-virginica   Iris-virginica
128   Iris-virginica   Iris-virginica
129   Iris-virginica   Iris-virginica
130   Iris-virginica   Iris-virginica
131   Iris-virginica   Iris-virginica
132   Iris-virginica   Iris-virginica
133   Iris-virginica   Iris-virginica
134   Iris-virginica   Iris-virginica
135   Iris-virginica   Iris-virginica
136   Iris-virginica   Iris-virginica
137   Iris-virginica   Iris-virginica
138   Iris-virginica   Iris-virginica
139   Iris-virginica   Iris-virginica
140   Iris-virginica   Iris-virginica
141   Iris-virginica   Iris-virginica
142   Iris-virginica   Iris-virginica
143   Iris-virginica   Iris-virginica
144   Iris-virginica   Iris-virginica
145   Iris-virginica   Iris-virginica
146   Iris-virginica   Iris-virginica
147   Iris-virginica   Iris-virginica
148   Iris-virginica   Iris-virginica
149   Iris-virginica   Iris-virginica
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="kesimpulan">
<h2>Kesimpulan<a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h2>
<p><span class="math notranslate nohighlight">\(
\begin{array}{lcccc}
\hline
\textbf{Model} &amp; \textbf{Akurasi} \\
\hline
\text{Naive Bayes (diskritisasi)} &amp; 0.97 \\
\text{Naive Bayes (iris-asli)} &amp; 0.96 \\
\text{Decision Tree (diskritisasi)} &amp; 0.98 \\
\text{Decision Tree (iris-asli)} &amp; 1.00 \\
\hline
\end{array}
\)</span></p>
<p>Secara keseluruhan, Decision Tree menunjukkan kinerja yang lebih unggul dibandingkan Naive Bayes pada kedua jenis data.Pengolahan data (diskritisasi) memberikan dampak yang berbeda pada kedua model:</p>
<ul class="simple">
<li><p>Pada Naive Bayes, proses diskritisasi justru meningkatkan kinerja model dari 0.96 menjadi 0.97. Ini menunjukkan bahwa model Naive Bayes dalam kasus ini bekerja lebih baik dengan fitur-fitur yang bersifat kategorikal (hasil diskritisasi).</p></li>
<li><p>Pada Decision Tree, proses diskritisasi sedikit menurunkan kinerja model dari 1.00 menjadi 0.98. Hal ini menandakan bahwa Decision Tree mampu memanfaatkan informasi dari data numerik kontinu pada set data Iris asli secara lebih efektif untuk mencapai hasil yang sempurna.</p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="decisiontree.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Decision Tree</p>
      </div>
    </a>
    <a class="right-next"
       href="heart_disease.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Implementasi Model Klasifikasi untuk Prediksi Tingkat Keparahan Penyakit Jantung Berdasarkan Data Medis</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clusterisasi-dengan-k-means">Clusterisasi dengan K-Means</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cari-min-max-dan-centroid-dari-fitur-sepal-length">Cari Min Max dan Centroid dari fitur sepal length</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-diskritisasi-fitur-sepal-length">Hasil Diskritisasi fitur sepal length</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mengganti-fitur-sepal-length-numeriks-ke-sepal-length-kategorikal">Mengganti fitur sepal_length(numeriks) ke sepal_length (kategorikal)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#melakukan-proses-diskritisasi-dengan-k-means-clustering-pada-fitur-lainya">Melakukan proses diskritisasi dengan K-means clustering pada fitur lainya</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#menampilkan-semua-data-hasil-diskritisasi-setiap-fitur">Menampilkan semua data hasil diskritisasi setiap fitur</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-naive-bayes-data-diskrit">Klasifikasi Naive Bayes Data Diskrit</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-naive-bayes-data-tanpa-diskritisasi">Klasifikasi Naive Bayes Data Tanpa Diskritisasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-decision-tree-data-diskrit">Klasifikasi Decision Tree Data Diskrit</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#klasifikasi-decision-tree-data-tanpa-diskritisasi">Klasifikasi Decision Tree Data Tanpa Diskritisasi</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">Kesimpulan</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Nabiilah Rizqi Amalia
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>